{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_bert",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qxq9I4dLAEk",
        "colab_type": "code",
        "outputId": "753367d1-861c-4398-9fa9-4245d6164092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51igRgf-u3Gk",
        "colab_type": "text"
      },
      "source": [
        "# Download Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rtslStCtFa7",
        "colab_type": "code",
        "outputId": "904cdb7d-7f56-4cfe-fe95-f22da8046b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install -q keras-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO2gUg0YtSEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-hBX7dptTxW",
        "colab_type": "code",
        "outputId": "5e23682a-b5c4-4aaf-9380-4bb251acc5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!unzip -o chinese_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  chinese_L-12_H-768_A-12.zip\n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: chinese_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw1WebIoKxZJ",
        "colab_type": "text"
      },
      "source": [
        "# clone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZzbQ7fYLHS6",
        "colab_type": "code",
        "outputId": "4d26781d-f115-41f5-8995-9170f0a1e113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My Drive/ntp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ntp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GvAkJnfKz7F",
        "colab_type": "code",
        "outputId": "de7cffb0-70ca-4b9e-fd54-f01ceaaa9db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/CyberZHG/keras-bert keras-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-bert'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 1047 (delta 87), reused 64 (delta 41), pack-reused 913\u001b[K\n",
            "Receiving objects: 100% (1047/1047), 14.09 MiB | 12.85 MiB/s, done.\n",
            "Resolving deltas: 100% (653/653), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZdcSZD-vAic",
        "colab_type": "text"
      },
      "source": [
        "# Build Model & Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ0khv6MHALN",
        "colab_type": "text"
      },
      "source": [
        "(這裡用的是預設的模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laquxnrzYCwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pretrained_path = 'chinese_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRYt_TnetY-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['TF_KERAS'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKC7jXvHtaju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leAEdmvCBXh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "token_dict_inv = {v: k for k, v in token_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EysHHcjYtb0U",
        "colab_type": "code",
        "outputId": "dac480e4-978b-49b0-9c16-0ee1899f5741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True)\n",
        "model.summary(line_length=120)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 12:01:57.572898 140186760062848 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0809 12:01:58.222465 140186760062848 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "________________________________________________________________________________________________________________________\n",
            "Layer (type)                           Output Shape               Param #       Connected to                            \n",
            "========================================================================================================================\n",
            "Input-Token (InputLayer)               [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)             [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding)       [(None, 512, 768), (21128, 16226304      Input-Token[0][0]                       \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)          (None, 512, 768)           1536          Input-Segment[0][0]                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)          (None, 512, 768)           0             Embedding-Token[0][0]                   \n",
            "                                                                                Embedding-Segment[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmbedding) (None, 512, 768)           393216        Embedding-Token-Segment[0][0]           \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)            (None, 512, 768)           0             Embedding-Position[0][0]                \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalization)    (None, 512, 768)           1536          Embedding-Dropout[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Embedding-Norm[0][0]                    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Embedding-Norm[0][0]                    \n",
            "                                                                                Encoder-1-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-1-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-1-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-1-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-1-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-1-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-1-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-2-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-2-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-2-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-2-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-2-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-2-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-2-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-3-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-3-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-3-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-3-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-3-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-3-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-3-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-4-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-4-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-4-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-4-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-4-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-4-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-4-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-5-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-5-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-5-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-5-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-5-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-5-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-5-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-6-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-6-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-6-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-6-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-6-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-6-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-6-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-7-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-7-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-7-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-7-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-7-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-7-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-7-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-8-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-8-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-8-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-8-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-8-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-8-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-8-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-9-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-9-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-9-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-9-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-9-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-9-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-9-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-10-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-10-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-10-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-10-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-10-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-10-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-10-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-11-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-11-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-11-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-11-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-11-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-11-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-11-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-12-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-12-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-12-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-12-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-12-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)                      (None, 512, 768)           590592        Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)          (None, 512, 768)           1536          MLM-Dense[0][0]                         \n",
            "________________________________________________________________________________________________________________________\n",
            "Extract (Extract)                      (None, 768)                0             Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)          (None, 512, 21128)         21128         MLM-Norm[0][0]                          \n",
            "                                                                                Embedding-Token[0][1]                   \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)              [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)                      (None, 768)                590592        Extract[0][0]                           \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM (Masked)                           (None, 512, 21128)         0             MLM-Sim[0][0]                           \n",
            "                                                                                Input-Masked[0][0]                      \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP (Dense)                            (None, 2)                  1538          NSP-Dense[0][0]                         \n",
            "========================================================================================================================\n",
            "Total params: 102,882,442\n",
            "Trainable params: 102,882,442\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luGqA58SvePv",
        "colab_type": "text"
      },
      "source": [
        "# Predict Masked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pUo3fA1vOdN",
        "colab_type": "code",
        "outputId": "14ecacab-0e2a-4b7e-bb89-6fc6cedbd910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras_bert import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "text = '等到潮水退了，就知道誰沒穿褲子'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "#tokens[3] = '[MASK]'\n",
        "print('Tokens:', tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens: ['[CLS]', '等', '到', '潮', '水', '退', '了', '，', '就', '知', '道', '誰', '沒', '穿', '褲', '子', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvOv05hxvVU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "masks = np.array([[0, 1, 1] + [0] * (512 - 3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP-tZdB4Ra_4",
        "colab_type": "code",
        "outputId": "fefdd61a-0437-444b-df17-6e5ceb34bdfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_len = len(text)\n",
        "text_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQx_DXeAvXGl",
        "colab_type": "code",
        "outputId": "2b80cfce-fa36-4cc7-9ea6-de48db66424a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predicts = model.predict([indices, segments, masks])[0].argmax(axis=-1).tolist()\n",
        "sentences= list(map(lambda x: token_dict_inv[x], predicts[0][3:4]))\n",
        "print('Fill with: ', ''.join(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fill with:  汗\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePe8Aa7uSzHX",
        "colab_type": "text"
      },
      "source": [
        "# My Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lEt7u9_HMX0",
        "colab_type": "text"
      },
      "source": [
        "(錯字偵測的程式碼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnsWcO4hS25L",
        "colab_type": "code",
        "outputId": "1996b283-f1f0-464d-e49f-4678cd3ab780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text = '吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。'\n",
        "text_wrong = 0\n",
        "for i in range(0,len(tokens)):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  if tokens[i] in ['，','。','、','[CLS]','[SEP]','：','\"','！']:\n",
        "      continue\n",
        "  tokens[i] = '[MASK]'\n",
        "  # print(tokens)\n",
        "  indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "  segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "  masks = np.array([[0, 1, 1] + [0] * (512 - 3)])\n",
        "  \n",
        "  predicts = model.predict([indices, segments, masks])[0].argmax(axis=-1).tolist()\n",
        "  sentences= list(map(lambda x: token_dict_inv[x], predicts[0][i:i+1]))\n",
        "  if ''.join(sentences) != text[i-1] :\n",
        "    print(''.join(tokens[1:len(tokens)-1]), '\\n建議字: ', ''.join(sentences))\n",
        "    text_wrong += 1\n",
        "print('預測錯字數目:',text_wrong,'錯誤率',text_wrong/len(tokens))    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MASK]光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  李\n",
            "吳[MASK]勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  得\n",
            "吳光[MASK]打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  榮\n",
            "吳光勝[MASK]開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  推\n",
            "吳光勝打開[MASK]門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  木\n",
            "吳光勝打開房門，[MASK]游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  將\n",
            "吳光勝打開房門，鬱[MASK]標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  元\n",
            "吳光勝打開房門，鬱游[MASK]在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  舟\n",
            "吳光勝打開房門，鬱游標在他[MASK]上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  身\n",
            "吳光勝打開房門，鬱游標在他背[MASK]重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  後\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，[MASK]進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  走\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進[MASK]內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  房\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門[MASK]，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  外\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上[MASK]門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  房\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽[MASK]喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  他\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得[MASK]喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  喇\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀[MASK]一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  嚓\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇[MASK]\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  。\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你[MASK]無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  對\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講[MASK]不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  講\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？[MASK]可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  你\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這[MASK]不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  人\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當[MASK]了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  成\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作[MASK]犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  是\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了[MASK]人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  敵\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不[MASK]官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  在\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官[MASK]，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  兵\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂[MASK]人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  殺\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關[MASK]？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  門\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"[MASK]是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  只\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可[MASK]外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  見\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面[MASK]息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  氣\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲[MASK]遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  音\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息[MASK]然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  嘩\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽[MASK]，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  止\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，[MASK]他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  令\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他[MASK]長氣，心想：\"既來之，則安之。 \n",
            "建議字:  喘\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大[MASK]氣，心想：\"既來之，則安之。 \n",
            "建議字:  喘\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長[MASK]，心想：\"既來之，則安之。 \n",
            "建議字:  老\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來[MASK]，則安之。 \n",
            "建議字:  此\n",
            "預測錯字數目: 40 錯誤率 0.3669724770642202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LinNj3MoiTm",
        "colab_type": "text"
      },
      "source": [
        "# load my model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQgXKpfOHSTt",
        "colab_type": "text"
      },
      "source": [
        "(塞自己訓練完的model 做法在readme裡面"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7bWTpJrS2_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_path = 'my_chinese_lm'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hh8-X5HZoU",
        "colab_type": "text"
      },
      "source": [
        "(vocab.txt跟bert_config用bert的，bert_model.ckpt用自己的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sGG0D35Hqkp",
        "colab_type": "text"
      },
      "source": [
        "(訓練完應該是叫bert_model_15000.ckpt，手動改名成bert_model.ckpt就好"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScfIAc6tdvyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "token_dict_inv = {v: k for k, v in token_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lobFUnN3rIQM",
        "colab_type": "code",
        "outputId": "be732c78-0d95-4a3f-e487-547fd57a1e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True)\n",
        "model.summary(line_length=120)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "________________________________________________________________________________________________________________________\n",
            "Layer (type)                           Output Shape               Param #       Connected to                            \n",
            "========================================================================================================================\n",
            "Input-Token (InputLayer)               (None, 512)                0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)             (None, 512)                0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding)       [(None, 512, 768), (21128, 16226304      Input-Token[0][0]                       \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)          (None, 512, 768)           1536          Input-Segment[0][0]                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)          (None, 512, 768)           0             Embedding-Token[0][0]                   \n",
            "                                                                                Embedding-Segment[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmbedding) (None, 512, 768)           393216        Embedding-Token-Segment[0][0]           \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)            (None, 512, 768)           0             Embedding-Position[0][0]                \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalization)    (None, 512, 768)           1536          Embedding-Dropout[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Embedding-Norm[0][0]                    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Embedding-Norm[0][0]                    \n",
            "                                                                                Encoder-1-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-1-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-1-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-1-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-1-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-1-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-1-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-2-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-2-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-2-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-2-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-2-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-2-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-2-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-3-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-3-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-3-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-3-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-3-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-3-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-3-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-4-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-4-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-4-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-4-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-4-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-4-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-4-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-5-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-5-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-5-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-5-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-5-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-5-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-5-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-6-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-6-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-6-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-6-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-6-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-6-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-6-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-7-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-7-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-7-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-7-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-7-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-7-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-7-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-8-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-8-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-8-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-8-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-8-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-8-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-8-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-9-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-9-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-9-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-9-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-9-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-9-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-9-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-10-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-10-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-10-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-10-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-10-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-10-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-10-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-11-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-11-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-11-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-11-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-11-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-11-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-11-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-12-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-12-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-12-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-12-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-12-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)                      (None, 512, 768)           590592        Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)          (None, 512, 768)           1536          MLM-Dense[0][0]                         \n",
            "________________________________________________________________________________________________________________________\n",
            "Extract (Extract)                      (None, 768)                0             Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)          (None, 512, 21128)         21128         MLM-Norm[0][0]                          \n",
            "                                                                                Embedding-Token[0][1]                   \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)              (None, 512)                0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)                      (None, 768)                590592        Extract[0][0]                           \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM (Masked)                           (None, 512, 21128)         0             MLM-Sim[0][0]                           \n",
            "                                                                                Input-Masked[0][0]                      \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP (Dense)                            (None, 2)                  1538          NSP-Dense[0][0]                         \n",
            "========================================================================================================================\n",
            "Total params: 102,882,442\n",
            "Trainable params: 102,882,442\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhbM2ngasGuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer = Tokenizer(token_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnK16fxseDUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "masks = np.array([[0, 1, 1] + [0] * (512 - 3)])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v55wFcv_peRr",
        "colab_type": "code",
        "outputId": "5830a7f2-e6fc-4309-ca3a-8fca06aa95b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text = '\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "text_wrong = 0\n",
        "for i in range(0,len(tokens)):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  if tokens[i] in ['，','。','、','[CLS]','[SEP]','：','\"','！']:\n",
        "      continue\n",
        "  tokens[i] = '[MASK]'\n",
        "  # print(tokens)\n",
        "  indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "  segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "  masks = np.array([[0, 1, 1] + [0] * (512 - 3)])\n",
        "  \n",
        "  predicts = model.predict([indices, segments, masks])[0].argmax(axis=-1).tolist()\n",
        "  sentences= list(map(lambda x: token_dict_inv[x], predicts[0][i:i+1]))\n",
        "  if ''.join(sentences) != text[i-1] :\n",
        "    print(''.join(tokens[1:len(tokens)-1]), '\\n建議字: ', ''.join(sentences))\n",
        "    text_wrong += 1\n",
        "print('預測錯字數目:',text_wrong,'錯誤率',text_wrong/len(tokens))   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"段譽道：\"[MASK]手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  下\n",
            "\"段譽道：\"出手[MASK]重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  太\n",
            "\"段譽道：\"出手不[MASK]，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  得\n",
            "\"段譽道：\"出手不重，[MASK]還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  這\n",
            "\"段譽道：\"出手不重，那還[MASK]什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  有\n",
            "\"段譽道：\"出手不重，那還算什麼[MASK]仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  大\n",
            "\"段譽道：\"出手不重，那還算什麼報[MASK]？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  答\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？[MASK]是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  不\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我[MASK]非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  可\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非[MASK]不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  打\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，[MASK]是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  不\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要[MASK]你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  生\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是[MASK]氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  生\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你[MASK]，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  打\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉[MASK]眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  上\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，[MASK]聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  柔\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好[MASK]！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  啦\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！[MASK]打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  \"\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你[MASK]還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  一\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打[MASK]之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  了\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還[MASK]後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  手\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之[MASK]覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  ，\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後[MASK]得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  ，\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽[MASK]手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  出\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的[MASK]打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  臉\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手[MASK]下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  一\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打[MASK]，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  痛\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼[MASK]，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  睛\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見[MASK]似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  她\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈[MASK]道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  叫\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不[MASK]？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  了\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出[MASK]手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  左\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手[MASK]指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  食\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在[MASK]左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  他\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右[MASK]頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  臉\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕[MASK]一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  輕\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈[MASK]下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  兩\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，[MASK]道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  說\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"[MASK]是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  可\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼[MASK]下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  一\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩[MASK]重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  斤\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下[MASK]的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  痛\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重[MASK]，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  傷\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，[MASK]痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  你\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可[MASK]得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  打\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害[MASK]？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  了\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，[MASK]道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  說\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己[MASK]前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  面\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身[MASK]，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  上\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，[MASK]氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  空\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹[MASK]如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  笛\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣[MASK]蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  吹\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如[MASK]，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  風\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越[MASK]越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  吹\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越[MASK]，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  近\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一[MASK]捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  直\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，[MASK]了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  過\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，[MASK]道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  說\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好[MASK]，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  吧\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇[MASK]報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  都\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我[MASK]找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  去\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要[MASK]那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  跟\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找[MASK]\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  個\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"[MASK]子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  小\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，[MASK]不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  救\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去[MASK]得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  救\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不[MASK]的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  去\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得[MASK]！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  啦\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事[MASK]一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  我\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你[MASK]點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  半\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不[MASK]，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  怕\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人[MASK]忌諱，我可救不得你。 \n",
            "建議字:  的\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，[MASK]可救不得你。 \n",
            "建議字:  那\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可[MASK]不得你。 \n",
            "建議字:  去\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不[MASK]你。 \n",
            "建議字:  了\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得[MASK]。 \n",
            "建議字:  了\n",
            "預測錯字數目: 76 錯誤率 0.3206751054852321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSct2EY7IBef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H9z9VaQ_q64",
        "colab_type": "text"
      },
      "source": [
        "# load my 15000 run step model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38MtovqwID1u",
        "colab_type": "text"
      },
      "source": [
        "跟上一個load做法一樣 只是這個模型跑比較多個run step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgSc74R2_qid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_path = 'my_chinese_lm_15000'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HMnDyBoBi6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "token_dict_inv = {v: k for k, v in token_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fr032jnBdGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True)\n",
        "#model.summary(line_length=120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y84u-xwLBvTv",
        "colab_type": "code",
        "outputId": "b2a6220c-855b-414a-bca8-91e03052db5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "from keras_bert import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "\n",
        "indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "masks = np.array([[0, 1, 1] + [0] * (512 - 3)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-a0d047d64938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNLrCwQsCGGm",
        "colab_type": "code",
        "outputId": "51aa89ae-e2e8-4b34-b521-c43a989390da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "text = '\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "text_wrong = 0\n",
        "for i in range(0,len(tokens)):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  if tokens[i] in ['，','。','、','[CLS]','[SEP]','：','\"','！']:\n",
        "      continue\n",
        "  tokens[i] = '[MASK]'\n",
        "  # print(tokens)\n",
        "  indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "  segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "  masks = np.array([[0, 1, 1] + [0] * (512 - 3)])\n",
        "  \n",
        "  predicts = model.predict([indices, segments, masks])[0].argmax(axis=-1).tolist()\n",
        "  sentences= list(map(lambda x: token_dict_inv[x], predicts[0][i:i+1]))\n",
        "  if ''.join(sentences) != text[i-1] :\n",
        "    print(''.join(tokens[1:len(tokens)-1]), '\\n建議字: ', ''.join(sentences))\n",
        "    text_wrong += 1\n",
        "print('預測錯字數目:',text_wrong,'錯誤率',text_wrong/len(tokens))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"段譽道：\"出手[MASK]重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  太\n",
            "\"段譽道：\"出手不[MASK]，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  打\n",
            "\"段譽道：\"出手不重，[MASK]還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  這\n",
            "\"段譽道：\"出手不重，那還[MASK]什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  有\n",
            "\"段譽道：\"出手不重，那還算什麼[MASK]仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  大\n",
            "\"段譽道：\"出手不重，那還算什麼報[MASK]？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  復\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？[MASK]是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  要\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我[MASK]非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  說\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非[MASK]不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  打\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要[MASK]你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  了\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是[MASK]氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  斷\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你[MASK]，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  說\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉[MASK]眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  上\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好[MASK]！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  啦\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你[MASK]還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  一\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打[MASK]之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  完\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之[MASK]覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  ，\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後[MASK]得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  ，\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽[MASK]手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  左\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的[MASK]打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  臉\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手[MASK]下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  一\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打[MASK]，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  軟\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見[MASK]似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  她\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似[MASK]非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  嗔\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不[MASK]？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  動\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右[MASK]頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  臉\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈[MASK]下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  兩\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"[MASK]是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  又\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼[MASK]下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  一\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩[MASK]重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  斤\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下[MASK]的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  下\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重[MASK]，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  彈\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，[MASK]痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  你\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己[MASK]前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  面\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身[MASK]，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  旁\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過[MASK]許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  丈\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，[MASK]氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  秀\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹[MASK]如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  淡\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣[MASK]蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  幽\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越[MASK]，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  喜\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得[MASK]開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  放\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，[MASK]了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  過\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好[MASK]，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  吧\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我[MASK]大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  連\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇[MASK]報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  都\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也[MASK]過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  不\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，[MASK]要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  偏\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我[MASK]找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  去\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要[MASK]那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  跟\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找[MASK]\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  個\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"[MASK]子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  呆\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，[MASK]不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  說\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不[MASK]的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  了\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得[MASK]！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  啊\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事[MASK]一點兒也不懂，犯了人家忌諱，我可救不得你。 \n",
            "建議字:  情\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，[MASK]可救不得你。 \n",
            "建議字:  那\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可[MASK]不得你。 \n",
            "建議字:  管\n",
            "\"段譽道：\"出手不重，那還算什麼報仇？我是非重不可，要是你氣，閉了眼睛，低聲道：\"好吧！你打還之後覺得段譽的手打下，睜開眼來，只見他似笑非笑的瞧著自己，鐘靈奇道：\"你怎麼還不打？\"段譽伸出右手小指，在她左右雙頰上分別輕彈一下，笑道：\"就是這麼兩下重的，可痛得厲害麼？\"鐘靈大喜，笑道：\"在自己身前，相距不過尺許，吹氣如蘭，越看越美，一時捨不得離開，隔了良久，才道：\"好啦，我的大仇也報過了，我要找那\"傻子，去不得的！江湖上的事你一點兒也不懂，犯了人家忌諱，我可救不[MASK]你。 \n",
            "建議字:  了\n",
            "預測錯字數目: 58 錯誤率 0.24472573839662448\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}