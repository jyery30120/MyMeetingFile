{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_bert.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2ywRFXQKc_g",
        "colab_type": "text"
      },
      "source": [
        "# num_train_steps設20的預訓練範例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxBoyMzLMyyx",
        "colab_type": "code",
        "outputId": "d5181b82-db6d-49b7-d671-29e54ac3f0ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGRChFZ3C6fe",
        "colab_type": "code",
        "outputId": "b7393ea1-7fb0-4b56-dc37-f7bb79965f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd drive/My Drive/ntp/bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ntp/bert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CETOflxODzOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! export BERT_BASE_DIR=./chinese_L-12_H-768_A-12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InVmv-mDIej1",
        "colab_type": "text"
      },
      "source": [
        "下面input_file 是自己要訓練的文本位置\n",
        "\n",
        "output_file是要輸出的位置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQn5BaTNDOBT",
        "colab_type": "code",
        "outputId": "31ed132f-aa43-450e-8ec1-da1ca46acf64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python create_pretraining_data.py \\\n",
        "  --input_file=data/corpusSegDone.txt \\\n",
        "  --output_file=modd/tf_examples.tfrecord \\\n",
        "  --vocab_file=chinese_L-12_H-768_A-12/vocab.txt \\\n",
        "  --do_lower_case=True \\\n",
        "  --max_seq_length=128 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --masked_lm_prob=0.15 \\\n",
        "  --random_seed=12345 \\\n",
        "  --dupe_factor=5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0818 14:35:10.781664 140329619232640 deprecation_wrapper.py:119] From create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0818 14:35:10.782480 140329619232640 deprecation_wrapper.py:119] From create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0818 14:35:10.782659 140329619232640 deprecation_wrapper.py:119] From create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0818 14:35:10.782798 140329619232640 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0818 14:35:11.406605 140329619232640 deprecation_wrapper.py:119] From create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0818 14:35:11.411568 140329619232640 deprecation_wrapper.py:119] From create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0818 14:35:11.411720 140329619232640 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "I0818 14:35:11.411793 140329619232640 create_pretraining_data.py:448]   data/corpusSegDone.txt\n",
            "I0818 14:35:48.584492 140329619232640 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "I0818 14:35:48.584684 140329619232640 create_pretraining_data.py:459]   modd/tf_examples.tfrecord\n",
            "W0818 14:35:48.584859 140329619232640 deprecation_wrapper.py:119] From create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I0818 14:35:48.905426 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.905662 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 去 [MASK] 大 理 ， ' 姑 蘇 [MASK] 容 ' 武 功 [MASK] 高 ， 萬 裡 外 發 出 ' 韋 陀 杵 ' 拳 ##萁 [MASK] 人 性 命 的 本 ： \" 道 ： \" 非 也 ， 非 也 ！ \" [MASK] 譽 一 [MASK] ， 心 [MASK] ： [MASK] [MASK] 說 你 的 話 有 ##皎 ， [SEP] ， 心 想 ： ' 這 黑 衣 漢 子 的 [MASK] 氣 當 真 [MASK] 怪 ， 退 後 幾 步 [MASK] 讓 他 一 讓 ， 也 就 是 [MASK] ， 和 [MASK] 個 挑 糞 擔 的 鄉 下 人 這 [MASK] 面 對 面 的 幹 耗 ， 有 什 麼 味 [MASK] ？ 聽 他 二 人 [SEP]\n",
            "I0818 14:35:48.905796 140329619232640 create_pretraining_data.py:161] input_ids: 101 1343 103 1920 4415 8024 112 1996 5979 103 2159 112 3636 1216 103 7770 8024 5857 6174 1912 4634 1139 112 7500 7351 3348 112 2891 18898 103 782 2595 1462 4638 3315 8038 107 6887 8038 107 7478 738 8024 7478 738 8013 107 103 6363 671 103 8024 2552 103 8038 103 103 6303 872 4638 6282 3300 17700 8024 102 8024 2552 2682 8038 112 6857 7946 6132 4031 2094 4638 103 3706 4534 4696 103 2597 8024 6842 2527 2407 3635 103 6366 800 671 6366 8024 738 2218 3221 103 8024 1469 103 943 2904 5135 3085 4638 6965 678 782 6857 103 7481 2205 7481 4638 2402 5450 8024 3300 784 7938 1456 103 8043 5481 800 753 782 102\n",
            "I0818 14:35:48.905932 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.906045 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.906122 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 2 9 14 28 29 47 50 53 55 56 62 76 80 87 96 99 109 114 121 0\n",
            "I0818 14:35:48.906194 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 6882 2710 7426 1213 1357 3667 2585 2682 107 2769 4415 5569 1367 8024 749 6857 7938 2402 6887 0\n",
            "I0818 14:35:48.906275 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.906337 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0818 14:35:48.906754 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.906900 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 身 來 到 中 土 ， 本 意 [MASK] [MASK] 識 一 下 少 林 寺 的 風 範 [MASK] 且 看 [MASK] 號 稱 中 原 武 林 [MASK] 山 北 [MASK] 之 地 ， 是 怎 [MASK] 一 副 [MASK] 嚴 [MASK] 偉 [MASK] 氣 象 。 但 聽 了 ##姹 位 高 僧 的 言 語 ， [MASK] 了 各 位 高 僧 的 舉 止 ， 嘿 嘿 嘿 ， 似 乎 還 及 不 上 僻 處 南 [MASK] 的 [SEP] 唉 [MASK] [MASK] 可 人 說 道 ： \" [MASK] 理 [MASK] 龍 寺 枯 榮 大 師 和 本 因 方 丈 佛 法 淵 深 ， 凡 我 釋 氏 弟 子 ， 無 不 仰 慕 。 [SEP]\n",
            "I0818 14:35:48.907011 140329619232640 create_pretraining_data.py:161] input_ids: 101 6716 889 1168 704 1759 8024 3315 2692 103 103 6352 671 678 2208 3360 2191 4638 7591 5061 103 684 4692 103 5998 4935 704 1333 3636 3360 103 2255 1266 103 722 1765 8024 3221 2582 103 671 1199 103 1713 103 971 103 3706 6496 511 852 5481 749 15068 855 7770 1014 4638 6241 6295 8024 103 749 1392 855 7770 1014 4638 5647 3632 8024 1678 1678 1678 8024 849 725 6917 1350 679 677 1020 5993 1298 103 4638 102 1536 103 103 1377 782 6303 6887 8038 107 103 4415 103 7983 2191 3369 3532 1920 2374 1469 3315 1728 3175 675 867 3791 3920 3918 8024 1127 2769 7026 3694 2475 2094 8024 4192 679 814 2710 511 102\n",
            "I0818 14:35:48.907111 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.907213 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.907280 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 9 10 20 23 30 33 39 42 44 46 51 53 61 70 84 88 89 96 98 0\n",
            "I0818 14:35:48.907359 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 2682 6210 8024 6857 3805 3159 3564 5800 2131 4638 5481 6328 4692 8024 4538 8013 6857 1920 1921 0\n",
            "I0818 14:35:48.907432 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.907493 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.907886 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.908021 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 那 大 [MASK] people 形 巨 大 ， 兵 刃 又 極 [MASK] 重 ， 殊 不 料 行 動 迅 捷 無 比 [MASK] 雙 [MASK] 互 擊 ， 將 好 將 長 劍 夾 在 雙 錘 之 中 。 [SEP] 八 角 銅 錘 每 κ 柄 各 有 四 十 來 斤 [MASK] 當 的 一 聲 呼 [MASK] 長 劍 登 時 斷 為 十 餘 截 ， 那 大 漢 飛 出 一 [MASK] [MASK] 踢 在 那 人 小 腹 之 上 。 那 人 [MASK] 叫 一 聲 [MASK] 跌 [MASK] 七 八 丈 外 人 手 舞 雙 [MASK] ， 沖 將 上 [MASK] ， 雙 刀 [MASK] 成 了 一 團 白 光 ， [MASK] 住 [SEP]\n",
            "I0818 14:35:48.908134 140329619232640 create_pretraining_data.py:161] input_ids: 101 6929 1920 103 8777 2501 2342 1920 8024 1070 1145 1348 3513 103 7028 8024 3654 679 3160 6121 1240 6813 2949 4192 3683 103 7427 103 757 3080 8024 2200 1962 2200 7269 1210 1933 1762 7427 7089 722 704 511 102 1061 6235 7067 7089 3680 218 3376 1392 3300 1724 1282 889 3165 103 4534 4638 671 5476 1461 103 7269 1210 4633 3229 3174 4158 1282 7626 2779 8024 6929 1920 4031 7606 1139 671 103 103 6677 1762 6929 782 2207 5592 722 677 511 6929 782 103 1373 671 5476 103 6649 103 673 1061 675 1912 782 2797 5659 7427 103 8024 3762 2200 677 103 8024 7427 1143 103 2768 749 671 1757 4635 1045 8024 103 857 102\n",
            "I0818 14:35:48.908239 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.908352 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.908427 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 3 4 13 25 27 31 49 56 57 63 80 81 93 97 99 108 113 117 125 0\n",
            "I0818 14:35:48.908498 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 4031 6716 3756 8024 7089 2200 671 3165 8024 8024 5597 8024 1920 8024 1139 1143 1343 5659 6362 0\n",
            "I0818 14:35:48.908569 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.908629 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.909033 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.909162 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 我 [MASK] 去 ！ 我 死 了 女 [MASK] ， 你 在 這 裡 胡 說 羥 道 什 [MASK] ？ [MASK] 蕭 峰 笑 道 ： \" ##總 [MASK] [MASK] 女 兒 ， 我 給 你 醫 活 來 如 何 ？ \" 一 伸 手 [MASK] [MASK] 向 那 少 在 那 少 女 腰 間 的 [MASK] 京 門 穴 ' 上 ， 這 是 人 身 最 末 一 根 肋 骨 [MASK] 尾 端 ， 蕭 峰 [SEP] 只 不 [MASK] 平 平 常 常 的 恭 [MASK] 師 父 ， 那 [MASK] 太 也 尋 [MASK] ， 與 師 父 你 老 人 家 古 往 [MASK] 來 第 一 高 人 的 身 分 殊 [MASK] 相 配 。 [SEP]\n",
            "I0818 14:35:48.909272 140329619232640 create_pretraining_data.py:161] input_ids: 101 2769 103 1343 8013 2769 3647 749 1957 103 8024 872 1762 6857 6174 5529 6303 5409 6887 784 103 8043 103 5941 2292 5010 6887 8038 107 18301 103 103 1957 1051 8024 2769 5183 872 7015 3833 889 1963 862 8043 107 671 847 2797 103 103 1403 6929 2208 1762 6929 2208 1957 5587 7279 4638 103 776 7271 4954 112 677 8024 6857 3221 782 6716 3297 3314 671 3418 5490 7755 103 2227 4999 8024 5941 2292 102 1372 679 103 2398 2398 2382 2382 4638 2621 103 2374 4266 8024 6929 103 1922 738 2204 103 8024 5645 2374 4266 872 5439 782 2157 1367 2518 103 889 5018 671 7770 782 4638 6716 1146 3654 103 4685 6981 511 102\n",
            "I0818 14:35:48.909373 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.909475 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.909541 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 2 4 9 17 20 22 29 30 31 48 49 60 77 86 93 98 102 113 123 0\n",
            "I0818 14:35:48.909610 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 1139 8013 1051 1061 7938 107 872 3647 749 8024 912 112 4638 6882 6313 2218 2382 791 679 0\n",
            "I0818 14:35:48.909682 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.909741 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0818 14:35:48.910116 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.910241 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 道 [MASK] \" 包 先 生 請 [MASK] 這 邊 休 去 和 王 語 嫣 相 聚 ， 公 主 見 與 不 見 [MASK] 毫 不 要 緊 ， 當 即 上 前 ， 黑 暗 中 仍 是 深 深 一 揖 ， 說 道 ： [MASK] 在 下 大 理 [MASK] 譽 ， 謹 向 公 主 殿 下 [SEP] [MASK] 南 疆 ， [MASK] 日 [MASK] 得 上 國 觀 光 ， 多 \" 原 來 是 大 理 國 鎮 南 王 世 [MASK] ， 王 [MASK] 不 [MASK] 多 謹 ， 勞 步 遠 [MASK] ， 實 深 簡 慢 ， 蝸 居 [MASK] 地 ， 不 足 以 接 貴 ﹔ ， 還 請 [MASK] 多 擔 代 [SEP]\n",
            "I0818 14:35:48.910352 140329619232640 create_pretraining_data.py:161] input_ids: 101 6887 103 107 1259 1044 4495 6313 103 6857 6920 828 1343 1469 4374 6295 2073 4685 5471 8024 1062 712 6210 5645 679 6210 103 3690 679 6206 5215 8024 4534 1315 677 1184 8024 7946 3266 704 793 3221 3918 3918 671 2992 8024 6303 6887 8038 103 1762 678 1920 4415 103 6363 8024 6346 1403 1062 712 3671 678 102 103 1298 4538 8024 103 3189 103 2533 677 1751 6223 1045 8024 1914 107 1333 889 3221 1920 4415 1751 7120 1298 4374 686 103 8024 4374 103 679 103 1914 6346 8024 1246 3635 6895 103 8024 2179 3918 5080 2714 8024 6080 2233 103 1765 8024 679 6639 809 2970 6523 8003 8024 6917 6313 103 1914 3085 807 102\n",
            "I0818 14:35:48.910453 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.910556 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.910624 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 2 7 8 26 50 52 55 65 69 71 81 82 90 93 95 102 111 119 123 0\n",
            "I0818 14:35:48.910694 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 8038 6313 1762 8024 107 678 3667 2233 791 2533 889 3221 2094 2094 7519 889 722 2145 1914 0\n",
            "I0818 14:35:48.910765 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.910839 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.911195 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.911315 140329619232640 create_pretraining_data.py:151] tokens: [CLS] \" 阿 紫 道 總 [MASK] 什 麼 ' 是 你 傷 的 ， 不 是 [MASK] 傷 的 ' ， [MASK] [MASK] 你 招 認 了 。 [SEP] 他 沒 死 ， 受 的 傷 也 不 是 ' 三 陰 蜈 蚣 瓜 ' . . . . . . [MASK] 紫 搶 著 [MASK] ： \" 不 是 三 陰 蜈 蚣 爪 ？ 那 麼 [MASK] 是 ' 抽 髓 [MASK] ' 了 ， 這 [MASK] [MASK] [MASK] 拿 [MASK] 本 領 ， 二 師 哥 不 小 心 中 了 你 的 [MASK] 算 ， 你 . . . [MASK] 如 [MASK] ， 怒 叫 ： \" [MASK] 師 哥 ##nda 動 手 ， 把 這 小 賤 人 拿 [MASK] [SEP]\n",
            "I0818 14:35:48.911424 140329619232640 create_pretraining_data.py:161] input_ids: 101 107 7350 5166 6887 5244 103 784 7938 112 3221 872 1003 4638 8024 679 3221 103 1003 4638 112 8024 103 103 872 2875 6291 749 511 102 800 3760 3647 8024 1358 4638 1003 738 679 3221 112 676 7374 6048 6017 4478 112 119 119 119 119 119 119 103 5166 3024 5865 103 8038 107 679 3221 676 7374 6048 6017 4259 8043 6929 7938 103 3221 112 2853 7767 103 112 749 8024 6857 103 103 103 2897 103 3315 7526 8024 753 2374 1520 679 2207 2552 704 749 872 4638 103 5050 8024 872 119 119 119 103 1963 103 8024 2584 1373 8038 107 103 2374 1520 12715 1240 2797 8024 2828 6857 2207 6547 782 2897 103 102\n",
            "I0818 14:35:48.911521 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.911620 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.911684 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 5 6 17 22 23 53 57 70 75 80 81 82 84 98 105 107 113 116 126 0\n",
            "I0818 14:35:48.911752 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 8038 107 2769 1962 1557 7350 6887 2137 2958 3221 872 4638 2797 3266 119 7440 676 2571 749 0\n",
            "I0818 14:35:48.911835 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.911906 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.912257 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.912380 140329619232640 create_pretraining_data.py:151] tokens: [CLS] \" [MASK] 譽 心 中 一 寒 。 只 見 [MASK] 夫 人 漫 [MASK] 在 乎 的 點 點 頭 ， 說 道 ： \" 段 公 子 ， 請 [MASK] \" 段 譽 [MASK] ： \" 冒 [MASK] 打 擾 ， 賢 主 [MASK] 勿 怪 是 幸 [MASK] [SEP] 你 說 [MASK] 道 我 身 世 真 相 ， 又 說 此 [MASK] 與 本 [MASK] [MASK] 危 有 關 ， 到 底 直 相 如 何 ， 卻 又 不 [MASK] [MASK] 實 [MASK] \" 說 到 這 裡 ， [MASK] 法 刀 還 入 包 袱 中 包 起 ， [MASK] 入 自 己 懷 中 ， 說 道 ： \" [MASK] 煽 動 叛 亂 ， 一 死 難 免 [SEP]\n",
            "I0818 14:35:48.912490 140329619232640 create_pretraining_data.py:161] input_ids: 101 107 103 6363 2552 704 671 2170 511 1372 6210 103 1923 782 4035 103 1762 725 4638 7953 7953 7531 8024 6303 6887 8038 107 3667 1062 2094 8024 6313 103 107 3667 6363 103 8038 107 1088 103 2802 3101 8024 6545 712 103 1257 2597 3221 2401 103 102 872 6303 103 6887 2769 6716 686 4696 4685 8024 1348 6303 3634 103 5645 3315 103 103 1314 3300 7302 8024 1168 2419 4684 4685 1963 862 8024 1320 1348 679 103 103 2179 103 107 6303 1168 6857 6174 8024 103 3791 1143 6917 1057 1259 6160 704 1259 6629 8024 103 1057 5632 2346 2755 704 8024 6303 6887 8038 107 103 4218 1240 1361 748 8024 671 3647 7432 1048 102\n",
            "I0818 14:35:48.912589 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.912699 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.927916 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 2 11 15 32 36 40 46 51 55 66 69 70 85 86 88 91 95 106 117 0\n",
            "I0818 14:35:48.928047 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 3667 4374 679 8013 6887 3218 782 511 4761 752 2396 2128 3140 1402 511 1168 2200 3123 872 0\n",
            "I0818 14:35:48.928152 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.928245 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0818 14:35:48.928771 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.928964 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 慕 容 複 等 各 較 一 招 ， 雖 然 占 了 上 [MASK] ， 卻 已 試 出 這 三 大 高 手 每 一 個 都 身 [MASK] [MASK] 技 ， 三 人 聯 手 ， 自 己 便 非 其 敵 ， 何 況 此 [MASK] 虎 視 [MASK] 眈 、 環 伺 ##灿 側 的 ， [MASK] [MASK] [SEP] ， 不 枉 了 結 義 一 場 ， [MASK] 也 罷 ， 活 也 罷 ， 大 家 [MASK] 氣 所 激 ， 接 過 一 隻 [MASK] 袋 ， [MASK] [MASK] [MASK] \" [MASK] 錯 ， 正 突 然 走 出 一 名 灰 衣 僧 人 ， [MASK] 聲 說 [MASK] [MASK] \" 大 哥 ， 三 弟 ， [SEP]\n",
            "I0818 14:35:48.929134 140329619232640 create_pretraining_data.py:161] input_ids: 101 2710 2159 6185 5023 1392 6733 671 2875 8024 7426 4197 1304 749 677 103 8024 1320 2347 6275 1139 6857 676 1920 7770 2797 3680 671 943 6963 6716 103 103 2825 8024 676 782 5474 2797 8024 5632 2346 912 7478 1071 3147 8024 862 3785 3634 103 5988 6213 103 4690 510 4472 848 17193 979 4638 8024 103 103 102 8024 679 3356 749 5178 5412 671 1842 8024 103 738 5394 8024 3833 738 5394 8024 1920 2157 103 3706 2792 4080 8024 2970 6882 671 7407 103 6150 8024 103 103 103 107 103 7097 8024 3633 4960 4197 6624 1139 671 1399 4129 6132 1014 782 8024 103 5476 6303 103 103 107 1920 1520 8024 676 2475 8024 102\n",
            "I0818 14:35:48.929280 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.929430 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.929531 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 15 28 31 32 50 53 58 62 63 74 84 93 96 97 98 100 115 118 119 0\n",
            "I0818 14:35:48.929629 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 7591 943 6511 5179 1912 4690 1762 3291 3300 3647 4578 4649 6303 6887 8038 679 3306 6887 8038 0\n",
            "I0818 14:35:48.929731 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.929819 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.930401 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.930575 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 阻 擋 ， 都 是 慢 了 一 步 ， 被 他 閃 身 搶 過 。 大 [MASK] [MASK] [MASK] 少 人 dhl 得 ， 此 人 [MASK] 是 庭 [MASK] ， 身 形 微 晃 ， 已 奔 峥 大 廳 ， 抓 起 譚 青 ， 疾 向 [MASK] 神 醫 [MASK] 來 。 廳 上 眾 人 都 怕 [SEP] ， 向 玄 寂 道 ： \" 稟 報 首 座 [MASK] 玄 慈 方 丈 [MASK] 杖 完 畢 。 \" 玄 寂 點 了 點 頭 站 起 [MASK] 來 [MASK] 向 葉 [MASK] 娘 虛 點 一 指 ， 想 icon 開 [MASK] 穴 道 ##鮑 不 料 重 傷 [MASK] 餘 ， [MASK] 氣 難 以 凝 聚 [SEP]\n",
            "I0818 14:35:48.930718 140329619232640 create_pretraining_data.py:161] input_ids: 101 7349 3081 8024 6963 3221 2714 749 671 3635 8024 6158 800 7272 6716 3024 6882 511 1920 103 103 103 2208 782 13305 2533 8024 3634 782 103 3221 2431 103 8024 6716 2501 2544 3230 8024 2347 1944 2286 1920 2453 8024 2831 6629 6354 7471 8024 4565 1403 103 4868 7015 103 889 511 2453 677 4707 782 6963 2586 102 8024 1403 4371 2163 6887 8038 107 4931 1841 7674 2429 103 4371 2705 3175 675 103 3335 2130 4525 511 107 4371 2163 7953 749 7953 7531 4991 6629 103 889 103 1403 5864 103 2023 5995 7953 671 2900 8024 2682 9734 7274 103 4954 6887 20857 679 3160 7028 1003 103 7626 8024 103 3706 7432 809 1125 5471 102\n",
            "I0818 14:35:48.930845 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.930969 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.931042 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 19 20 21 24 29 32 41 52 55 76 81 95 97 100 108 110 113 118 121 0\n",
            "I0818 14:35:48.931112 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 2453 677 679 6291 718 704 1057 5955 3762 8024 1358 6716 8024 753 6237 1961 8024 722 4696 0\n",
            "I0818 14:35:48.931185 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.931245 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0818 14:35:48.932388 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.932549 140329619232640 create_pretraining_data.py:151] tokens: [CLS] ， 對 [MASK] [MASK] \" [MASK] 兒 \" 相 稱 也 不 反 口 ， [MASK] 感 奇 怪 攔 只 有 朱 丹 臣 等 人 明 白 其 中 下 ， 心 下 [MASK] 念 [MASK] \" 我 師 父 常 [MASK] ， 佛 祖 傳 下 的 修 證 法 門 是 戒 、 定 、 慧 三 學 。 [SEP] \" 鳩 摩 智 微 笑 道 ： \" 不 敢 ！ 段 公 子 怎 麼 [MASK] 隨 殿 [MASK] 前 來 ？ \" [MASK] [MASK] 淳 汤 [MASK] \" 犬 子 [MASK] 知 去 了 何 處 ， 說 不 定 又 落 入 了 奸 人 惡 [MASK] 之 手 ， 正 要 向 國 [MASK] 請 教 。 [SEP]\n",
            "I0818 14:35:48.932685 140329619232640 create_pretraining_data.py:161] input_ids: 101 8024 2205 103 103 107 103 1051 107 4685 4935 738 679 1353 1366 8024 103 2697 1936 2597 3105 1372 3300 3319 710 5628 5023 782 3209 4635 1071 704 678 8024 2552 678 103 2573 103 107 2769 2374 4266 2382 103 8024 867 4862 1001 678 4638 934 6349 3791 7271 3221 2770 510 2137 510 2716 676 2119 511 102 107 7853 3040 3255 2544 5010 6887 8038 107 679 3140 8013 3667 1062 2094 2582 7938 103 7401 3671 103 1184 889 8043 107 103 103 3919 3739 103 107 4305 2094 103 4761 1343 749 862 5993 8024 6303 679 2137 1348 5862 1057 749 1960 782 2670 103 722 2797 8024 3633 6206 1403 1751 103 6313 3136 511 102\n",
            "I0818 14:35:48.932796 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.932922 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.932993 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 3 4 6 16 20 36 38 44 82 85 90 91 93 94 98 103 115 116 123 0\n",
            "I0818 14:35:48.933061 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 800 809 2530 6963 511 6752 8038 6303 679 678 3667 3633 6887 8038 679 5993 1014 722 2374 0\n",
            "I0818 14:35:48.933133 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.933192 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0818 14:35:48.933575 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.933703 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 則 三 四 十 年 ， 只 [MASK] [MASK] 量 洞 洞 主 等 少 數 幾 位 ， [MASK] 是 近 年 來 歸 屬 [MASK] 鷲 宮 治 下 的 。 反 正 誰 也 沒 見 過 她 面 ， 誰 也 裡 ， 心 想 [MASK] [MASK] 量 ##兇 洞 主 倒 是 素 [MASK] ， 四 下 打 [SEP] 乘 微 蹙 ， 心 道 ： \" 你 一 動 不 動 [MASK] 瑾 在 那 裡 ， 我 既 [MASK] [MASK] 你 [MASK] 派 [MASK] 又 不 知 你 姓 名 ， 怎 知 你 最 擅 長 镍 [MASK] 什 麼 絕 招 ？ 不 知 你 有 什 麼 [MASK] 道 ' [MASK] 際 ， 那 大 頭 [SEP]\n",
            "I0818 14:35:48.933815 140329619232640 create_pretraining_data.py:161] input_ids: 101 1179 676 1724 1282 2399 8024 1372 103 103 7030 3822 3822 712 5023 2208 3149 2407 855 8024 103 3221 6818 2399 889 3645 2253 103 7876 2152 3780 678 4638 511 1353 3633 6306 738 3760 6210 6882 1961 7481 8024 6306 738 6174 8024 2552 2682 103 103 7030 14100 3822 712 948 3221 5162 103 8024 1724 678 2802 102 733 2544 6694 8024 2552 6887 8038 107 872 671 1240 679 1240 103 4458 1762 6929 6174 8024 2769 3188 103 103 872 103 3836 103 1348 679 4761 872 1998 1399 8024 2582 4761 872 3297 3078 7269 7255 103 784 7938 5179 2875 8043 679 4761 872 3300 784 7938 103 6887 112 103 7396 8024 6929 1920 7531 102\n",
            "I0818 14:35:48.933936 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.934039 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.934105 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 8 9 20 26 27 50 51 53 59 78 79 86 87 89 91 105 106 118 121 0\n",
            "I0818 14:35:48.934175 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 3300 4192 2798 2253 7470 6929 4192 3822 6352 4638 1777 679 4761 7271 8024 4638 3221 112 722 0\n",
            "I0818 14:35:48.934247 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.934307 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0818 14:35:48.934665 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.934788 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 他 是 有 德 高 僧 ， 也 不 [MASK] 氣 ， 只 微 微 一 笑 [MASK] 心 道 ： \" 這 群 人 個 個 瘋 瘋 顛 顛 [MASK] [SEP] 味 相 投 ， 這 [MASK] [MASK] ： \" 玄 苦 啊 玄 苦 [MASK] 我 為 [MASK] 報 答 知 已 苦 心 [MASK] 詣 的 又 替 你 創 了 一 [MASK] 新 曲 ， [MASK] 做 [MASK] 一 葦 吟 ' ， 頌 揚 你 [MASK] 尕 寺 始 祖 達 摩 老 祖 一 葦 渡 皋 江 偉 績 。 你 [MASK] 麼 [MASK] 不 聽 了 ？ \" 忽 然 轉 著 向 玄 難 [MASK] ： \" 玄 苦 師 [MASK] 的 墳 墓 在 [MASK] [SEP]\n",
            "I0818 14:35:48.934913 140329619232640 create_pretraining_data.py:161] input_ids: 101 800 3221 3300 2548 7770 1014 8024 738 679 103 3706 8024 1372 2544 2544 671 5010 103 2552 6887 8038 107 6857 5408 782 943 943 4597 4597 7545 7545 103 102 1456 4685 2832 8024 6857 103 103 8038 107 4371 5736 1557 4371 5736 103 2769 4158 103 1841 5031 4761 2347 5736 2552 103 6274 4638 1348 3296 872 1201 749 671 103 3173 3289 8024 103 976 103 671 5870 1412 112 8024 7520 2993 872 103 2210 2191 1993 4862 6888 3040 5439 4862 671 5870 3941 4642 3736 971 5245 511 872 103 7938 103 679 5481 749 8043 107 2575 4197 6752 5865 1403 4371 7432 103 8038 107 4371 5736 2374 103 4638 1877 1867 1762 103 102\n",
            "I0818 14:35:48.935014 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.935116 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.935182 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 10 18 32 39 40 48 51 58 67 71 73 82 83 94 100 102 115 121 126 0\n",
            "I0818 14:35:48.935250 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 4495 8024 511 1526 6887 8024 749 4316 7674 1373 112 2208 3360 679 2582 738 6887 1040 1525 0\n",
            "I0818 14:35:48.935321 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.935387 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.935740 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.935876 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 王 府 中 出 來 ， 段 [MASK] 妃 刀 白 鳳 和 鐘 萬 仇 向 她 [MASK] 呼 ， 她 聽 而 不 聞 ， 逕 自 掩 面 疾 奔 。 ##lvin 覺 [MASK] [MASK] 大 [MASK] ， [MASK] 無 一 處 安 身 之 所 。 在 荒 山 野 嶺 中 亂 闖 亂 [MASK] [MASK] 直 到 黎 明 ， 只 累 得 兩 腿 酸 軟 ， 這 才 停 步 ， 靠 在 一 株 大 樹 ##濾 上 [MASK] 頓 足 叫 道 ： [MASK] 我 [SEP] \" 段 郎 [MASK] 非 對 我 負 心 ##粵 幸 ， 只 因 陰 差 陽 錯 ， 偏 偏 僻 是 我 同 父 的 哥 哥 。 [SEP]\n",
            "I0818 14:35:48.935987 140329619232640 create_pretraining_data.py:161] input_ids: 101 4374 2424 704 1139 889 8024 3667 103 1964 1143 4635 7854 1469 7132 5857 790 1403 1961 103 1461 8024 1961 5481 5445 679 5472 8024 6855 5632 2973 7481 4565 1944 511 12745 6221 103 103 1920 103 8024 103 4192 671 5993 2128 6716 722 2792 511 1762 5774 2255 7029 2327 704 748 7300 748 103 103 4684 1168 7944 3209 8024 1372 5168 2533 1060 5597 7000 6727 8024 6857 2798 977 3635 8024 7479 1762 671 3415 1920 3572 17156 677 103 7524 6639 1373 6887 8038 103 2769 102 107 3667 6947 103 7478 2205 2769 6511 2552 18178 2401 8024 1372 1728 7374 2345 7382 7097 8024 974 974 1020 3221 2769 1398 4266 4638 1520 1520 511 102\n",
            "I0818 14:35:48.936088 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.936188 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.936254 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 8 19 35 37 38 40 42 47 57 59 60 61 64 86 88 94 100 106 112 0\n",
            "I0818 14:35:48.936321 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 4374 2875 1372 5818 5818 1765 1086 6716 748 748 1944 8024 7944 722 8024 107 699 5946 2345 0\n",
            "I0818 14:35:48.936400 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.936460 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.936809 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.936946 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 小 子 虛 張 聲 勢 ， 招 搖 撞 騙 [MASK] 雖 然 繚 [MASK] 相 傳 ， 我 段 家 有 六 脈 神 劍 奇 功 ， [MASK] [MASK] 不 出 手 ， 只 道 他 有 意 [MASK] 此 ， 當 [MASK] 站 [MASK] 一 [MASK] ， 靜 觀 其 變 。 又 過 [MASK] 一 陣 ， 二 十 余 [MASK] 聾 [MASK] 漢 子 在 火 柱 燒 炙 之 下 [MASK] 死 了 大 半 ， 其 [MASK] 小 半 也 [SEP] 鑼 鼓 聲 中 ， 丁 春 秋 袍 [MASK] 揮 ##moon 兩 揮 ， 火 柱 ： \" 休 得 傷 我 師 父 ！ \" 縱 身 要 擋 到 火 [MASK] 之 前 。 [SEP]\n",
            "I0818 14:35:48.937055 140329619232640 create_pretraining_data.py:161] input_ids: 101 2207 2094 5995 2484 5476 1248 8024 2875 3015 3058 7700 103 7426 4197 5253 103 4685 1001 8024 2769 3667 2157 3300 1063 5548 4868 1210 1936 1216 8024 103 103 679 1139 2797 8024 1372 6887 800 3300 2692 103 3634 8024 4534 103 4991 103 671 103 8024 7477 6223 1071 6365 511 1348 6882 103 671 7369 8024 753 1282 865 103 5482 103 4031 2094 1762 4125 3393 4240 4147 722 678 103 3647 749 1920 1288 8024 1071 103 2207 1288 738 102 7147 7961 5476 704 8024 672 3217 4904 6151 103 3000 12682 1060 3000 8024 4125 3393 8038 107 828 2533 1003 2769 2374 4266 8013 107 5241 6716 6206 3081 1168 4125 103 722 1184 511 102\n",
            "I0818 14:35:48.937156 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.937257 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.937323 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 12 15 16 31 32 36 42 46 48 50 59 66 68 78 85 98 99 101 123 0\n",
            "I0818 14:35:48.937399 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 511 3125 5439 6363 699 8024 1963 678 1762 3178 2533 943 1563 2347 7626 6151 6153 749 3393 0\n",
            "I0818 14:35:48.937470 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:48.937529 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:48.937895 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:48.938021 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 他 調 運 內 息 [MASK] 此 快 [MASK] ， 直 [MASK] 意 到 即 至 ， 這 一 陽 指 的 造 詣 ， 可 比 我 深 得 多 了 [MASK] \" 當 即 [MASK] 指 還 出 [MASK] 只 是 他 慢 [MASK] 瞬 他 [MASK] [MASK] 已 久 ， 深 恐 夜 長 夢 多 ， 倘 若 他 群 [MASK] 部 屬 一 [MASK] book 上 ， 終 究 多 費 手 腳 ， 當 下 運 棒 如 風 ， 頃 刻 [SEP] ##爱 正 淳 奮 力 抵 擋 ， 到 第 九 [MASK] 上 [MASK] 真 氣 不 繼 [MASK] ? 的 [MASK] 聲 [MASK] 響 ， 鐵 棒 棒 頭 插 入 了 他 左 肩 。 [SEP]\n",
            "I0818 14:35:48.938130 140329619232640 create_pretraining_data.py:161] input_ids: 101 800 6310 6880 1058 2622 103 3634 2571 103 8024 4684 103 2692 1168 1315 5635 8024 6857 671 7382 2900 4638 6863 6274 8024 1377 3683 2769 3918 2533 1914 749 103 107 4534 1315 103 2900 6917 1139 103 1372 3221 800 2714 103 4746 800 103 103 2347 719 8024 3918 2607 1915 7269 1918 1914 8024 951 5735 800 5408 103 6956 2253 671 103 9106 677 8024 5173 4955 1914 6527 2797 5589 8024 4534 678 6880 3472 1963 7591 8024 7516 1174 102 17320 3633 3919 1956 1213 2850 3081 8024 1168 5018 736 103 677 103 4696 3706 679 5262 103 136 4638 103 5476 103 7513 8024 7136 3472 3472 7531 2991 1057 749 800 2340 5504 511 102\n",
            "I0818 14:35:48.938230 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:48.938330 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.030783 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 6 9 12 33 37 41 46 49 50 65 69 70 90 101 103 108 111 113 119 0\n",
            "I0818 14:35:49.030954 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 1963 3791 849 511 671 8024 749 3683 2874 5628 3075 5445 3667 3472 8024 8024 671 6738 7531 0\n",
            "I0818 14:35:49.031065 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:49.031149 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:49.031684 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:49.031881 140329619232640 create_pretraining_data.py:151] tokens: [CLS] \" 什 麼 ' 小 無 相 [MASK] [MASK] ？ \" 童 姥 ##und 呆 舺 隨 即 定 神 ， 拭 幹 了 眼 里 鏢 歎 了 口 氣 ， 道 [MASK] [MASK] 沒 什 麼 誦 歌 訣 之 時 [MASK] 在 [MASK] 多 難 關 上 都 迅 速 通 過 [MASK] 倒 背 [MASK] 尤 其 顯 得 流 暢 ， 童 姥 [MASK] 地 裡 想 起 ， 那 [MASK] 是 [MASK] [SEP] \" 阿 朱 道 ： \" 你 小 時 候 ， 你 媽 媽 可 有 唱 歌 給 你 聽 ？ [MASK] 喬 峰 [MASK] 了 搔 頭 ， 道 ： \" 那 [MASK] 好 像 有 的 ， 不 過 我 都 忘 了 。 [SEP]\n",
            "I0818 14:35:49.032054 140329619232640 create_pretraining_data.py:161] input_ids: 101 107 784 7938 112 2207 4192 4685 103 103 8043 107 4997 2005 9914 1438 5671 7401 1315 2137 4868 8024 2887 2402 749 4706 7027 7129 3626 749 1366 3706 8024 6887 103 103 3760 784 7938 6301 3625 6254 722 3229 103 1762 103 1914 7432 7302 677 6963 6813 6862 6858 6882 103 948 5520 103 2215 1071 7549 2533 3837 3268 8024 4997 2005 103 1765 6174 2682 6629 8024 6929 103 3221 103 102 107 7350 3319 6887 8038 107 872 2207 3229 952 8024 872 2061 2061 1377 3300 1548 3625 5183 872 5481 8043 103 1605 2292 103 749 3014 7531 8024 6887 8038 107 6929 103 1962 1008 3300 4638 8024 679 6882 2769 6963 2563 749 511 102\n",
            "I0818 14:35:49.032206 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.032361 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.032470 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 8 9 14 16 26 27 33 34 35 44 46 56 59 69 76 78 102 105 114 0\n",
            "I0818 14:35:49.032572 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 1216 112 671 8024 3907 8024 6887 8038 107 8024 6258 8024 3229 4338 2137 934 107 3014 948 0\n",
            "I0818 14:35:49.032674 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:49.032762 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "I0818 14:35:49.033300 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:49.033462 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 蕭 峰 來 者 [MASK] 拒 ， 一 一 照 吃 。 [SEP] [MASK] 一 筷 ， [MASK] 道 ： \" 臭 [MASK] [MASK] [MASK] 的 ， 只 配 ##吒 豬 [MASK] 吃 。 \" 抓 起 羊 羔 ： [MASK] 魚 ： 豬 肉 ， 去 擦 ##筛 子 。 酒 保 [MASK] 然 ##碚 [MASK] 尋 思 ： \" 這 小 魔 頭 當 真 討 厭 ， 給 她 纏 [MASK] 了 身 ， 後 患 無 窮 。 阿 朱 ##no [MASK] 照 [MASK] 她 ， 這 人 是 個 鬼 精 靈 ， 她 要 照 自 己 綽 綽 有 餘 ， 壓 根 兒 用 不 著 我 操 心 。 我 還 是 避 之 ， 忽 [MASK] [SEP]\n",
            "I0818 14:35:49.033588 140329619232640 create_pretraining_data.py:161] input_ids: 101 5941 2292 889 5442 103 2867 8024 671 671 4212 1391 511 102 103 671 5039 8024 103 6887 8038 107 5634 103 103 103 4638 8024 1372 6981 14461 6500 103 1391 511 107 2831 6629 5399 5402 8038 103 7797 8038 6500 5489 8024 1343 3092 18090 2094 511 6983 924 103 4197 17872 103 2204 2590 8038 107 6857 2207 7795 7531 4534 4696 6245 1339 8024 5183 1961 5267 103 749 6716 8024 2527 2642 4192 4981 511 7350 3319 8609 103 4212 103 1961 8024 6857 782 3221 943 7787 5125 7470 8024 1961 6206 4212 5632 2346 5212 5212 3300 7626 8024 1886 3418 1051 4500 679 5865 2769 3082 2552 511 2769 6917 3221 6912 722 8024 2575 103 102\n",
            "I0818 14:35:49.033701 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.033807 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.033900 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 5 14 18 23 24 25 30 32 41 49 54 56 57 74 81 85 86 88 126 0\n",
            "I0818 14:35:49.033972 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 679 749 912 4638 8024 4247 5183 4318 7805 7486 7426 1912 8024 677 4981 2805 2769 3160 6210 0\n",
            "I0818 14:35:49.034045 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:49.034105 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:49.034492 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:49.034619 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 但 他 只 是 個 孩 子 ， 有 什 麼 力 氣 ， 給 那 大 ##雖 抓 了 起 來 ， [MASK] 到 了 ##申 門 外 。 媽 媽 忙 [MASK] [MASK] 門 外 去 看 那 孩 子 。 那 [MASK] [MASK] 怕 那 女 子 再 來 糾 纏 ， 便 將 [MASK] 門 關 上 了 。 [SEP] 子 額 頭 撞 [MASK] 石 塊 上 ， 流 了 很 多 血 。 媽 媽 怕 事 ， [MASK] 敢 再 在 大 夫 門 前 逗 留 ， 便 一 路 [MASK] 泣 ， 拉 著 孩 [MASK] 一 [MASK] [MASK] 店 門 前 [MASK] 見 [MASK] 子 上 放 著 幾 把 殺 豬 殺 牛 的 [MASK] [SEP]\n",
            "I0818 14:35:49.034730 140329619232640 create_pretraining_data.py:161] input_ids: 101 852 800 1372 3221 943 2111 2094 8024 3300 784 7938 1213 3706 8024 5183 6929 1920 20483 2831 749 6629 889 8024 103 1168 749 17566 7271 1912 511 2061 2061 2564 103 103 7271 1912 1343 4692 6929 2111 2094 511 6929 103 103 2586 6929 1957 2094 1086 889 5144 5267 8024 912 2200 103 7271 7302 677 749 511 102 2094 7540 7531 3058 103 4767 1846 677 8024 3837 749 2523 1914 6117 511 2061 2061 2586 752 8024 103 3140 1086 1762 1920 1923 7271 1184 6856 4522 8024 912 671 6662 103 3798 8024 2861 5865 2111 103 671 103 103 2421 7271 1184 103 6210 103 2094 677 3123 5865 2407 2828 3669 6500 3669 4281 4638 103 102\n",
            "I0818 14:35:49.034846 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.034953 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.035022 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 18 24 27 28 34 35 45 46 58 69 85 95 99 105 107 108 112 114 126 0\n",
            "I0818 14:35:49.035092 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 1923 100 1920 7271 1944 1168 1920 1923 1920 1762 679 8024 1526 6882 2157 7136 8024 3113 2211 0\n",
            "I0818 14:35:49.035163 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:49.035223 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:49.035582 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:49.035708 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 各 人 [MASK] [MASK] 無 功 [MASK] 早 在 暗 暗 走 進 室 ##渦 ， 微 笑 道 ： \" 枯 榮 [MASK] 師 的 禪 [MASK] 非 同 小 可 ， 小 僧 甚 是 佩 服 。 那 六 脈 神 劍 嘛 ， [MASK] 然 只 是 徒 具 虛 名 而 已 。 [SEP] 當 年 慕 [MASK] 先 [MASK] 所 [MASK] 仰 的 ， 是 六 脈 [MASK] [MASK] 的 劍 法 ， 並 [MASK] 是 六 脈 神 劍 的 劍 陣 。 天 叵 寺 這 座 劍 陣 固 然 威 力 甚 大 ， 但 [MASK] [MASK] 量 ， 也 只 和 少 林 寺 [MASK] 羅 漢 劍 陣 、 昆 侖 [MASK] 的 混 [SEP]\n",
            "I0818 14:35:49.035818 140329619232640 create_pretraining_data.py:161] input_ids: 101 1392 782 103 103 4192 1216 103 3193 1762 3266 3266 6624 6868 2147 17002 8024 2544 5010 6887 8038 107 3369 3532 103 2374 4638 4890 103 7478 1398 2207 1377 8024 2207 1014 4493 3221 877 3302 511 6929 1063 5548 4868 1210 1658 8024 103 4197 1372 3221 2530 1072 5995 1399 5445 2347 511 102 4534 2399 2710 103 1044 103 2792 103 814 4638 8024 3221 1063 5548 103 103 4638 1210 3791 8024 699 103 3221 1063 5548 4868 1210 4638 1210 7369 511 1921 1382 2191 6857 2429 1210 7369 1743 4197 2014 1213 4493 1920 8024 852 103 103 7030 8024 738 1372 1469 2208 3360 2191 103 5397 4031 1210 7369 510 3204 895 103 4638 3921 102\n",
            "I0818 14:35:49.035937 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.036040 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.036107 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 3 4 7 15 24 28 48 63 65 67 74 75 81 89 92 106 107 116 124 0\n",
            "I0818 14:35:49.036176 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 719 2782 8024 1058 1920 1216 3362 2159 4495 3620 4868 1210 679 7369 7983 1041 1071 4638 3836 0\n",
            "I0818 14:35:49.036247 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:49.036308 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:35:49.036846 140329619232640 create_pretraining_data.py:149] *** Example ***\n",
            "I0818 14:35:49.036986 140329619232640 create_pretraining_data.py:151] tokens: [CLS] 沒 死 星 宿 老 怪 丁 春 秋 ， 一 眼 之 間 ， 便 已 認 清 了 對 [MASK] 諸 人 ， 手 [MASK] 羽 扇 揮 [MASK] 幾 揮 ， 說 道 ： ' 慕 華 賢 [MASK] ， 你 [MASK] 能 將 那 [MASK] 胖 的 少 林 僧 醫 好 ， [MASK] 可 饒 你 [MASK] 死 [MASK] 只 [MASK] 你 須 拜 [SEP] \" 他 [MASK] 心 一 意 只 是 薛 華 [MASK] 癒 慧 淨 [MASK] 帶 他 到 昆 口 氣 ， 竟 將 當 前 諸 人 全 放 [MASK] 眼 裡 ， 似 乎 [MASK] 人 [MASK] 生 死 存 亡 ， 全 可 由 他 隨 心 所 欲 的 [MASK] 置 。 [SEP]\n",
            "I0818 14:35:49.037109 140329619232640 create_pretraining_data.py:161] input_ids: 101 3760 3647 3215 2162 5439 2597 672 3217 4904 8024 671 4706 722 7279 8024 912 2347 6291 3926 749 2205 103 6328 782 8024 2797 103 5417 2794 3000 103 2407 3000 8024 6303 6887 8038 112 2710 5836 6545 103 8024 872 103 5543 2200 6929 103 5523 4638 2208 3360 1014 7015 1962 8024 103 1377 7641 872 103 3647 103 1372 103 872 7519 2876 102 107 800 103 2552 671 2692 1372 3221 5955 5836 103 4618 2716 3912 103 2380 800 1168 3204 1366 3706 8024 4994 2200 4534 1184 6328 782 1059 3123 103 4706 6174 8024 849 725 103 782 103 4495 3647 2100 767 8024 1059 1377 4507 800 7401 2552 2792 3617 4638 103 5390 511 102\n",
            "I0818 14:35:49.037219 140329619232640 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.037329 140329619232640 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0818 14:35:49.037410 140329619232640 create_pretraining_data.py:161] masked_lm_positions: 22 27 31 42 45 49 58 62 64 66 73 81 85 101 102 105 107 109 124 0\n",
            "I0818 14:35:49.037480 140329619232640 create_pretraining_data.py:161] masked_lm_ids: 3175 704 749 888 1963 5523 2769 679 8024 3221 671 3780 8024 1762 4706 849 1392 4638 5993 0\n",
            "I0818 14:35:49.037551 140329619232640 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0818 14:35:49.037611 140329619232640 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "I0818 14:36:00.281211 140329619232640 create_pretraining_data.py:166] Wrote 43657 total instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if-xCvH_EqUN",
        "colab_type": "code",
        "outputId": "f3cb0b7b-a663-4ce7-ac2c-f308f482eef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_pretraining.py \\\n",
        "  --input_file=modd/tf_examples.tfrecord \\\n",
        "  --output_dir=modd/pretraining_output \\\n",
        "  --do_train=True \\\n",
        "  --do_eval=True \\\n",
        "  --bert_config_file=chinese_L-12_H-768_A-12/bert_config.json \\\n",
        "  --init_checkpoint=chinese_L-12_H-768_A-12/bert_model.ckpt \\\n",
        "  --train_batch_size=32 \\\n",
        "  --max_seq_length=128 \\\n",
        "  --max_predictions_per_seq=20 \\\n",
        "  --num_train_steps=20 \\\n",
        "  --num_warmup_steps=10 \\\n",
        "  --learning_rate=2e-5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0818 14:37:18.786674 140708815394688 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0818 14:37:18.787552 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "W0818 14:37:18.788057 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0818 14:37:18.788181 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0818 14:37:18.788297 140708815394688 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0818 14:37:18.791644 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:414: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0818 14:37:18.795415 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:418: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0818 14:37:18.796435 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:420: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0818 14:37:18.796540 140708815394688 run_pretraining.py:420] *** Input Files ***\n",
            "I0818 14:37:18.796607 140708815394688 run_pretraining.py:422]   modd/tf_examples.tfrecord\n",
            "W0818 14:37:19.760353 140708815394688 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0818 14:37:19.761052 140708815394688 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff917f33620>) includes params argument, but params are not passed to Estimator.\n",
            "I0818 14:37:19.762349 140708815394688 estimator.py:209] Using config: {'_model_dir': 'modd/pretraining_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff909a74080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
            "I0818 14:37:19.762571 140708815394688 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
            "W0818 14:37:19.763086 140708815394688 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n",
            "I0818 14:37:19.763192 140708815394688 run_pretraining.py:459] ***** Running training *****\n",
            "I0818 14:37:19.763270 140708815394688 run_pretraining.py:460]   Batch size = 32\n",
            "W0818 14:37:19.769640 140708815394688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0818 14:37:19.784460 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0818 14:37:19.789769 140708815394688 deprecation.py:323] From run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0818 14:37:19.789904 140708815394688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0818 14:37:19.813023 140708815394688 deprecation.py:323] From run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0818 14:37:19.813150 140708815394688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0818 14:37:19.814290 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0818 14:37:19.819349 140708815394688 deprecation.py:323] From run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0818 14:37:19.846074 140708815394688 estimator.py:1145] Calling model_fn.\n",
            "I0818 14:37:19.846237 140708815394688 tpu_estimator.py:2965] Running train on CPU\n",
            "I0818 14:37:19.846547 140708815394688 run_pretraining.py:117] *** Features ***\n",
            "I0818 14:37:19.846671 140708815394688 run_pretraining.py:119]   name = input_ids, shape = (32, 128)\n",
            "I0818 14:37:19.846768 140708815394688 run_pretraining.py:119]   name = input_mask, shape = (32, 128)\n",
            "I0818 14:37:19.846885 140708815394688 run_pretraining.py:119]   name = masked_lm_ids, shape = (32, 20)\n",
            "I0818 14:37:19.846975 140708815394688 run_pretraining.py:119]   name = masked_lm_positions, shape = (32, 20)\n",
            "I0818 14:37:19.847062 140708815394688 run_pretraining.py:119]   name = masked_lm_weights, shape = (32, 20)\n",
            "I0818 14:37:19.847147 140708815394688 run_pretraining.py:119]   name = next_sentence_labels, shape = (32, 1)\n",
            "I0818 14:37:19.847234 140708815394688 run_pretraining.py:119]   name = segment_ids, shape = (32, 128)\n",
            "W0818 14:37:19.847426 140708815394688 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0818 14:37:19.848862 140708815394688 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0818 14:37:19.872861 140708815394688 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0818 14:37:19.908128 140708815394688 deprecation.py:506] From /content/drive/My Drive/ntp/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0818 14:37:19.922663 140708815394688 deprecation.py:323] From /content/drive/My Drive/ntp/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0818 14:37:22.877372 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:165: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "I0818 14:37:23.712858 140708815394688 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0818 14:37:23.713112 140708815394688 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.713291 140708815394688 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.713424 140708815394688 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.713623 140708815394688 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.713745 140708815394688 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.713929 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714046 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714123 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714200 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714271 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714369 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714442 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714513 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714580 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714644 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714709 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714777 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714858 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.714931 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715004 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715070 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715137 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715205 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715358 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715465 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715553 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715628 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715695 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715766 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715850 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715919 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.715991 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716060 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716125 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716271 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716372 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716449 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716516 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716587 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716651 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716719 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716844 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.716996 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717111 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717216 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717314 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717408 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717483 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717605 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717727 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717866 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.717944 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718060 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718130 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718200 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718267 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718335 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718400 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718469 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718535 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718603 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718703 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718851 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.718951 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719083 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719156 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719228 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719295 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719361 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719426 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719565 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719674 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719764 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719849 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719921 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.719992 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720062 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720129 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720195 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720306 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720440 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720537 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720613 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720680 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720745 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720811 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720894 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.720959 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721032 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721097 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721261 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721364 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721439 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721519 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721586 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721650 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721719 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721784 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721866 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.721931 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722063 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722192 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722288 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722366 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722454 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722526 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722607 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722676 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722815 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.722936 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723136 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723227 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723301 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723416 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723550 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723640 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723708 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723773 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.723861 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.758333 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.758466 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.758568 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.758678 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.758775 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.758896 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759023 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759122 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759230 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759328 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759424 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759521 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759616 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759707 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759798 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.759919 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760026 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760127 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760219 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760315 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760406 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760620 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760746 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760870 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.760971 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761085 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761181 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761279 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761373 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761481 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761578 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761675 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761767 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761885 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.761993 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762094 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762185 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762282 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762373 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762463 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762556 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762651 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762742 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.762852 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763145 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763252 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763345 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763440 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763530 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763625 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763711 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.763803 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.764081 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.764219 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.764326 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.764704 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.765089 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.765845 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766340 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766438 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766518 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766596 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766669 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766744 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766813 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766898 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.766965 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767041 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767108 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767177 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767243 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767308 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767373 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767442 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767508 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767577 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767643 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767707 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767770 140708815394688 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767848 140708815394688 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767914 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.767985 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.768051 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.768114 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.768177 140708815394688 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (21128,), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.768241 140708815394688 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:37:23.768307 140708815394688 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "W0818 14:37:23.768537 140708815394688 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0818 14:37:23.769930 140708815394688 deprecation_wrapper.py:119] From /content/drive/My Drive/ntp/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0818 14:37:23.775320 140708815394688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0818 14:37:23.981934 140708815394688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "I0818 14:37:31.755918 140708815394688 estimator.py:1147] Done calling model_fn.\n",
            "I0818 14:37:31.757323 140708815394688 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0818 14:37:34.838638 140708815394688 monitored_session.py:240] Graph was finalized.\n",
            "2019-08-18 14:37:34.843629: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-18 14:37:34.843857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ce8bc0 executing computations on platform Host. Devices:\n",
            "2019-08-18 14:37:34.843887: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-18 14:37:34.858403: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-18 14:37:35.028201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:37:35.028720: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ce99c0 executing computations on platform CUDA. Devices:\n",
            "2019-08-18 14:37:35.028750: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-08-18 14:37:35.028993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:37:35.029392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-18 14:37:35.029685: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-18 14:37:35.030666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-18 14:37:35.031688: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-18 14:37:35.032031: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-18 14:37:35.033282: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-18 14:37:35.034198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-18 14:37:35.036980: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-18 14:37:35.037098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:37:35.037485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:37:35.037842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-18 14:37:35.037907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-18 14:37:35.038804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-18 14:37:35.038844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-18 14:37:35.038857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-18 14:37:35.039147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:37:35.039531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:37:35.039887: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-18 14:37:35.039935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2019-08-18 14:37:54.698223: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "I0818 14:37:54.768051 140708815394688 session_manager.py:500] Running local_init_op.\n",
            "I0818 14:37:54.908157 140708815394688 session_manager.py:502] Done running local_init_op.\n",
            "I0818 14:38:01.275544 140708815394688 basic_session_run_hooks.py:606] Saving checkpoints for 0 into modd/pretraining_output/model.ckpt.\n",
            "2019-08-18 14:38:17.120182: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "I0818 14:38:23.544084 140708815394688 tpu_estimator.py:2159] global_step/sec: 0.196985\n",
            "I0818 14:38:23.545221 140708815394688 tpu_estimator.py:2160] examples/sec: 6.30352\n",
            "I0818 14:38:24.422871 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.13792\n",
            "I0818 14:38:24.423070 140708815394688 tpu_estimator.py:2160] examples/sec: 36.4135\n",
            "I0818 14:38:25.272074 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.17756\n",
            "I0818 14:38:25.272428 140708815394688 tpu_estimator.py:2160] examples/sec: 37.682\n",
            "I0818 14:38:26.116009 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.18493\n",
            "I0818 14:38:26.116360 140708815394688 tpu_estimator.py:2160] examples/sec: 37.9178\n",
            "I0818 14:38:26.961547 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.18265\n",
            "I0818 14:38:26.961913 140708815394688 tpu_estimator.py:2160] examples/sec: 37.8448\n",
            "I0818 14:38:27.809889 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.17889\n",
            "I0818 14:38:27.810323 140708815394688 tpu_estimator.py:2160] examples/sec: 37.7245\n",
            "I0818 14:38:28.654748 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.18351\n",
            "I0818 14:38:28.655115 140708815394688 tpu_estimator.py:2160] examples/sec: 37.8723\n",
            "I0818 14:38:29.507667 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.17249\n",
            "I0818 14:38:29.508084 140708815394688 tpu_estimator.py:2160] examples/sec: 37.5198\n",
            "I0818 14:38:30.357358 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.1769\n",
            "I0818 14:38:30.357744 140708815394688 tpu_estimator.py:2160] examples/sec: 37.6608\n",
            "I0818 14:38:31.208343 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.17507\n",
            "I0818 14:38:31.208540 140708815394688 tpu_estimator.py:2160] examples/sec: 37.6022\n",
            "I0818 14:38:32.060980 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.17285\n",
            "I0818 14:38:32.061184 140708815394688 tpu_estimator.py:2160] examples/sec: 37.5313\n",
            "I0818 14:38:32.909682 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.17824\n",
            "I0818 14:38:32.910069 140708815394688 tpu_estimator.py:2160] examples/sec: 37.7036\n",
            "I0818 14:38:33.764421 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.16995\n",
            "I0818 14:38:33.764621 140708815394688 tpu_estimator.py:2160] examples/sec: 37.4385\n",
            "I0818 14:38:34.619311 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.16976\n",
            "I0818 14:38:34.619703 140708815394688 tpu_estimator.py:2160] examples/sec: 37.4322\n",
            "I0818 14:38:35.474670 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.16909\n",
            "I0818 14:38:35.475024 140708815394688 tpu_estimator.py:2160] examples/sec: 37.4109\n",
            "I0818 14:38:36.328422 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.17128\n",
            "I0818 14:38:36.328626 140708815394688 tpu_estimator.py:2160] examples/sec: 37.4809\n",
            "I0818 14:38:37.185997 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.16612\n",
            "I0818 14:38:37.186210 140708815394688 tpu_estimator.py:2160] examples/sec: 37.3158\n",
            "I0818 14:38:38.044837 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.16435\n",
            "I0818 14:38:38.045210 140708815394688 tpu_estimator.py:2160] examples/sec: 37.2592\n",
            "I0818 14:38:38.901535 140708815394688 tpu_estimator.py:2159] global_step/sec: 1.16729\n",
            "I0818 14:38:38.901737 140708815394688 tpu_estimator.py:2160] examples/sec: 37.3534\n",
            "I0818 14:38:38.902552 140708815394688 basic_session_run_hooks.py:606] Saving checkpoints for 20 into modd/pretraining_output/model.ckpt.\n",
            "I0818 14:38:50.434153 140708815394688 estimator.py:368] Loss for final step: 2.843019.\n",
            "I0818 14:38:50.435039 140708815394688 error_handling.py:96] training_loop marked as finished\n",
            "I0818 14:38:50.435191 140708815394688 run_pretraining.py:469] ***** Running evaluation *****\n",
            "I0818 14:38:50.435271 140708815394688 run_pretraining.py:470]   Batch size = 8\n",
            "I0818 14:38:50.476920 140708815394688 estimator.py:1145] Calling model_fn.\n",
            "I0818 14:38:50.477108 140708815394688 tpu_estimator.py:2965] Running eval on CPU\n",
            "I0818 14:38:50.477423 140708815394688 run_pretraining.py:117] *** Features ***\n",
            "I0818 14:38:50.477547 140708815394688 run_pretraining.py:119]   name = input_ids, shape = (8, 128)\n",
            "I0818 14:38:50.477656 140708815394688 run_pretraining.py:119]   name = input_mask, shape = (8, 128)\n",
            "I0818 14:38:50.477747 140708815394688 run_pretraining.py:119]   name = masked_lm_ids, shape = (8, 20)\n",
            "I0818 14:38:50.477847 140708815394688 run_pretraining.py:119]   name = masked_lm_positions, shape = (8, 20)\n",
            "I0818 14:38:50.477934 140708815394688 run_pretraining.py:119]   name = masked_lm_weights, shape = (8, 20)\n",
            "I0818 14:38:50.478018 140708815394688 run_pretraining.py:119]   name = next_sentence_labels, shape = (8, 1)\n",
            "I0818 14:38:50.478107 140708815394688 run_pretraining.py:119]   name = segment_ids, shape = (8, 128)\n",
            "I0818 14:38:53.233215 140708815394688 run_pretraining.py:167] **** Trainable Variables ****\n",
            "I0818 14:38:53.233449 140708815394688 run_pretraining.py:173]   name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.233569 140708815394688 run_pretraining.py:173]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.233654 140708815394688 run_pretraining.py:173]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.233734 140708815394688 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.233808 140708815394688 run_pretraining.py:173]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.233900 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.233980 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234049 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234119 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234197 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234265 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234331 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234400 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234467 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234533 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234597 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234665 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234731 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234807 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234894 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.234972 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235037 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235107 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235173 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235243 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235308 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235376 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235443 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235511 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235576 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235639 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235703 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235773 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235851 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.235943 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236013 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236078 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236143 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236212 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236278 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236347 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236413 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236481 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236546 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236615 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236680 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236744 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236809 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236892 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.236964 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237032 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237098 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237162 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237226 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237294 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237358 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237426 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237491 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237559 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237624 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237691 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237756 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237819 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237897 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.237972 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238039 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238107 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238172 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238236 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238301 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238368 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238434 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238501 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238566 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238633 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238698 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238764 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238839 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238912 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.238977 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239045 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239111 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239177 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239241 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239304 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239367 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239434 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239498 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239564 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239627 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239693 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239757 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239833 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239901 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.239972 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240036 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240103 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240167 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240234 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240298 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240361 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240425 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240492 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240556 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240624 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240688 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240755 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240819 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240898 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.240968 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241033 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241104 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241181 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241250 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241318 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241382 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241446 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241511 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241578 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.241642 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.285603 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.285802 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.285962 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286065 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286178 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286275 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286369 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286462 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286579 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286676 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286774 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286889 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.286996 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287089 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287180 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287276 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287374 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287467 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287564 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287658 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287755 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287864 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.287971 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288066 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288163 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288258 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288355 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288447 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288540 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288634 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288729 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288836 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.288957 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289053 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289151 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289246 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289341 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289433 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289529 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289621 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289716 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289808 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.289931 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290027 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290118 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290210 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290309 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290403 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290504 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290598 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290698 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290793 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.290917 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291015 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291110 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291203 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291302 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291397 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291498 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291591 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291682 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291777 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291894 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.291998 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292100 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292191 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292289 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292387 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292486 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292579 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292673 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292766 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292881 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.292989 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293088 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293180 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293272 140708815394688 run_pretraining.py:173]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293365 140708815394688 run_pretraining.py:173]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293461 140708815394688 run_pretraining.py:173]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293553 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293648 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293739 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293844 140708815394688 run_pretraining.py:173]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.293950 140708815394688 run_pretraining.py:173]   name = cls/predictions/output_bias:0, shape = (21128,), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.294044 140708815394688 run_pretraining.py:173]   name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "I0818 14:38:53.294138 140708815394688 run_pretraining.py:173]   name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "W0818 14:38:53.301116 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:198: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
            "\n",
            "W0818 14:38:53.314958 140708815394688 deprecation_wrapper.py:119] From run_pretraining.py:202: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "I0818 14:38:53.355176 140708815394688 estimator.py:1147] Done calling model_fn.\n",
            "I0818 14:38:53.372024 140708815394688 evaluation.py:255] Starting evaluation at 2019-08-18T14:38:53Z\n",
            "I0818 14:38:53.835294 140708815394688 monitored_session.py:240] Graph was finalized.\n",
            "2019-08-18 14:38:53.835902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:38:53.836155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-18 14:38:53.836229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-18 14:38:53.836255: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-18 14:38:53.836275: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-18 14:38:53.836301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-18 14:38:53.836322: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-18 14:38:53.836340: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-18 14:38:53.836360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-18 14:38:53.836437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:38:53.836677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:38:53.836895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-18 14:38:53.836946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-18 14:38:53.836961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-18 14:38:53.836972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-18 14:38:53.837127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:38:53.837392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-18 14:38:53.837597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0818 14:38:53.837727 140708815394688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0818 14:38:53.839564 140708815394688 saver.py:1280] Restoring parameters from modd/pretraining_output/model.ckpt-20\n",
            "I0818 14:38:54.896222 140708815394688 session_manager.py:500] Running local_init_op.\n",
            "I0818 14:38:54.948289 140708815394688 session_manager.py:502] Done running local_init_op.\n",
            "I0818 14:38:56.328998 140708815394688 evaluation.py:167] Evaluation [10/100]\n",
            "I0818 14:38:57.033466 140708815394688 evaluation.py:167] Evaluation [20/100]\n",
            "I0818 14:38:57.730316 140708815394688 evaluation.py:167] Evaluation [30/100]\n",
            "I0818 14:38:58.430763 140708815394688 evaluation.py:167] Evaluation [40/100]\n",
            "I0818 14:38:59.134165 140708815394688 evaluation.py:167] Evaluation [50/100]\n",
            "I0818 14:38:59.836068 140708815394688 evaluation.py:167] Evaluation [60/100]\n",
            "I0818 14:39:00.538062 140708815394688 evaluation.py:167] Evaluation [70/100]\n",
            "I0818 14:39:01.241670 140708815394688 evaluation.py:167] Evaluation [80/100]\n",
            "I0818 14:39:01.941882 140708815394688 evaluation.py:167] Evaluation [90/100]\n",
            "I0818 14:39:02.646609 140708815394688 evaluation.py:167] Evaluation [100/100]\n",
            "I0818 14:39:02.742755 140708815394688 evaluation.py:275] Finished evaluation at 2019-08-18-14:39:02\n",
            "I0818 14:39:02.743027 140708815394688 estimator.py:2039] Saving dict for global step 20: global_step = 20, loss = 2.3872235, masked_lm_accuracy = 0.5819737, masked_lm_loss = 2.076379, next_sentence_accuracy = 0.8775, next_sentence_loss = 0.31084475\n",
            "I0818 14:39:03.210914 140708815394688 estimator.py:2099] Saving 'checkpoint_path' summary for global step 20: modd/pretraining_output/model.ckpt-20\n",
            "I0818 14:39:03.211694 140708815394688 error_handling.py:96] evaluation_loop marked as finished\n",
            "I0818 14:39:03.211931 140708815394688 run_pretraining.py:483] ***** Eval results *****\n",
            "I0818 14:39:03.212027 140708815394688 run_pretraining.py:485]   global_step = 20\n",
            "I0818 14:39:03.215758 140708815394688 run_pretraining.py:485]   loss = 2.3872235\n",
            "I0818 14:39:03.215913 140708815394688 run_pretraining.py:485]   masked_lm_accuracy = 0.5819737\n",
            "I0818 14:39:03.215996 140708815394688 run_pretraining.py:485]   masked_lm_loss = 2.076379\n",
            "I0818 14:39:03.216064 140708815394688 run_pretraining.py:485]   next_sentence_accuracy = 0.8775\n",
            "I0818 14:39:03.216130 140708815394688 run_pretraining.py:485]   next_sentence_loss = 0.31084475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G57wMKKQK9h2",
        "colab_type": "text"
      },
      "source": [
        "可以看到 跑出來的結果是0.58\n",
        "\n",
        "num_train_steps設15000 花一整個下午可以把acc從0.58提高到0.9\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvnGZZFbEg-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}