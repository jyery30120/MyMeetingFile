{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_bert",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qxq9I4dLAEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1b9d284c-6374-43ad-9ca7-701d28dbab43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51igRgf-u3Gk",
        "colab_type": "text"
      },
      "source": [
        "# Download Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rtslStCtFa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "142fe6e2-6265-4f72-f677-c314b0209727"
      },
      "source": [
        "!pip install -q keras-bert"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO2gUg0YtSEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-hBX7dptTxW",
        "colab_type": "code",
        "outputId": "5e23682a-b5c4-4aaf-9380-4bb251acc5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!unzip -o chinese_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  chinese_L-12_H-768_A-12.zip\n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: chinese_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: chinese_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw1WebIoKxZJ",
        "colab_type": "text"
      },
      "source": [
        "# clone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZzbQ7fYLHS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e96b867d-c7ac-4507-8eb3-1aefbf3b0728"
      },
      "source": [
        "cd drive/My Drive/ntp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ntp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GvAkJnfKz7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "de7cffb0-70ca-4b9e-fd54-f01ceaaa9db7"
      },
      "source": [
        "!git clone https://github.com/CyberZHG/keras-bert keras-bert"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-bert'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 1047 (delta 87), reused 64 (delta 41), pack-reused 913\u001b[K\n",
            "Receiving objects: 100% (1047/1047), 14.09 MiB | 12.85 MiB/s, done.\n",
            "Resolving deltas: 100% (653/653), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1YKrj0YOIpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fb881991-7595-4177-9955-80df173de105"
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mbert\u001b[0m/                     'Neural Style Transfer with Eager Execution.ipynb'\n",
            "\u001b[01;34m'Car Detection'\u001b[0m/           \u001b[01;34m'NLP in tensorflow'\u001b[0m/\n",
            " \u001b[01;34mchinese_L-12_H-768_A-12\u001b[0m/   \u001b[01;34mpycorrector\u001b[0m/\n",
            " \u001b[01;34meight\u001b[0m/                     \u001b[01;34mpytorch_transformers\u001b[0m/\n",
            " \u001b[01;34mglue\u001b[0m/                      \u001b[01;34mTom-Chang-Deep-Lyrics-master\u001b[0m/\n",
            " \u001b[01;34mkeras-bert\u001b[0m/                \u001b[01;34mudacity_intro_to_tensorflow_for_deep_learning\u001b[0m/\n",
            " \u001b[01;34mmachinetranslation\u001b[0m/        最重要的事.docx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEK2YahfQWVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZdcSZD-vAic",
        "colab_type": "text"
      },
      "source": [
        "# Build Model & Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99cDyL1VtWOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pretrained_path = 'chinese_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laquxnrzYCwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pretrained_path = 'chinese_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRYt_TnetY-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['TF_KERAS'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKC7jXvHtaju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "\n",
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "token_dict_inv = {v: k for k, v in token_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EysHHcjYtb0U",
        "colab_type": "code",
        "outputId": "dac480e4-978b-49b0-9c16-0ee1899f5741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True)\n",
        "model.summary(line_length=120)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 12:01:57.572898 140186760062848 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0809 12:01:58.222465 140186760062848 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "________________________________________________________________________________________________________________________\n",
            "Layer (type)                           Output Shape               Param #       Connected to                            \n",
            "========================================================================================================================\n",
            "Input-Token (InputLayer)               [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)             [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding)       [(None, 512, 768), (21128, 16226304      Input-Token[0][0]                       \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)          (None, 512, 768)           1536          Input-Segment[0][0]                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)          (None, 512, 768)           0             Embedding-Token[0][0]                   \n",
            "                                                                                Embedding-Segment[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmbedding) (None, 512, 768)           393216        Embedding-Token-Segment[0][0]           \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)            (None, 512, 768)           0             Embedding-Position[0][0]                \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalization)    (None, 512, 768)           1536          Embedding-Dropout[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Embedding-Norm[0][0]                    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Embedding-Norm[0][0]                    \n",
            "                                                                                Encoder-1-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-1-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-1-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-1-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-1-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-1-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-1-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-2-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-2-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-2-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-2-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-2-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-2-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-2-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-3-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-3-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-3-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-3-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-3-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-3-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-3-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-4-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-4-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-4-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-4-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-4-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-4-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-4-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-5-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-5-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-5-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-5-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-5-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-5-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-5-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-6-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-6-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-6-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-6-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-6-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-6-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-6-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-7-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-7-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-7-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-7-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-7-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-7-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-7-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-8-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-8-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-8-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-8-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-8-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-8-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-8-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-9-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-9-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-9-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-9-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-9-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-9-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-9-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-10-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-10-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-10-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-10-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-10-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-10-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-10-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-11-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-11-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-11-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-11-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-11-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-11-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-11-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-12-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-12-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-12-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-12-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-12-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)                      (None, 512, 768)           590592        Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)          (None, 512, 768)           1536          MLM-Dense[0][0]                         \n",
            "________________________________________________________________________________________________________________________\n",
            "Extract (Extract)                      (None, 768)                0             Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)          (None, 512, 21128)         21128         MLM-Norm[0][0]                          \n",
            "                                                                                Embedding-Token[0][1]                   \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)              [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)                      (None, 768)                590592        Extract[0][0]                           \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM (Masked)                           (None, 512, 21128)         0             MLM-Sim[0][0]                           \n",
            "                                                                                Input-Masked[0][0]                      \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP (Dense)                            (None, 2)                  1538          NSP-Dense[0][0]                         \n",
            "========================================================================================================================\n",
            "Total params: 102,882,442\n",
            "Trainable params: 102,882,442\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luGqA58SvePv",
        "colab_type": "text"
      },
      "source": [
        "# Predict Masked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pUo3fA1vOdN",
        "colab_type": "code",
        "outputId": "14ecacab-0e2a-4b7e-bb89-6fc6cedbd910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras_bert import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "text = '等到潮水退了，就知道誰沒穿褲子'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "#tokens[3] = '[MASK]'\n",
        "print('Tokens:', tokens)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens: ['[CLS]', '等', '到', '潮', '水', '退', '了', '，', '就', '知', '道', '誰', '沒', '穿', '褲', '子', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvOv05hxvVU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "masks = np.array([[0, 1, 1] + [0] * (512 - 3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP-tZdB4Ra_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fefdd61a-0437-444b-df17-6e5ceb34bdfb"
      },
      "source": [
        "text_len = len(text)\n",
        "text_len"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQx_DXeAvXGl",
        "colab_type": "code",
        "outputId": "2b80cfce-fa36-4cc7-9ea6-de48db66424a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predicts = model.predict([indices, segments, masks])[0].argmax(axis=-1).tolist()\n",
        "sentences= list(map(lambda x: token_dict_inv[x], predicts[0][3:4]))\n",
        "print('Fill with: ', ''.join(sentences))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fill with:  汗\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePe8Aa7uSzHX",
        "colab_type": "text"
      },
      "source": [
        "# My Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnsWcO4hS25L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1996b283-f1f0-464d-e49f-4678cd3ab780"
      },
      "source": [
        "text = '吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。'\n",
        "text_wrong = 0\n",
        "for i in range(0,len(tokens)):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  if tokens[i] in ['，','。','、','[CLS]','[SEP]','：','\"','！']:\n",
        "      continue\n",
        "  tokens[i] = '[MASK]'\n",
        "  # print(tokens)\n",
        "  indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "  segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "  masks = np.array([[0, 1, 1] + [0] * (512 - 3)])\n",
        "  \n",
        "  predicts = model.predict([indices, segments, masks])[0].argmax(axis=-1).tolist()\n",
        "  sentences= list(map(lambda x: token_dict_inv[x], predicts[0][i:i+1]))\n",
        "  if ''.join(sentences) != text[i-1] :\n",
        "    print(''.join(tokens[1:len(tokens)-1]), '\\n建議字: ', ''.join(sentences))\n",
        "    text_wrong += 1\n",
        "print('預測錯字數目:',text_wrong,'錯誤率',text_wrong/len(tokens))    "
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MASK]光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  李\n",
            "吳[MASK]勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  得\n",
            "吳光[MASK]打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  榮\n",
            "吳光勝[MASK]開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  推\n",
            "吳光勝打開[MASK]門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  木\n",
            "吳光勝打開房門，[MASK]游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  將\n",
            "吳光勝打開房門，鬱[MASK]標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  元\n",
            "吳光勝打開房門，鬱游[MASK]在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  舟\n",
            "吳光勝打開房門，鬱游標在他[MASK]上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  身\n",
            "吳光勝打開房門，鬱游標在他背[MASK]重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  後\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，[MASK]進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  走\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進[MASK]內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  房\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門[MASK]，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  外\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上[MASK]門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  房\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽[MASK]喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  他\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得[MASK]喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  喇\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀[MASK]一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  嚓\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇[MASK]\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  。\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你[MASK]無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  對\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講[MASK]不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  講\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？[MASK]可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  你\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這[MASK]不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  人\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當[MASK]了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  成\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作[MASK]犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  是\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了[MASK]人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  敵\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不[MASK]官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  在\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官[MASK]，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  兵\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂[MASK]人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  殺\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關[MASK]？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  門\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"[MASK]是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  只\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可[MASK]外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  見\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面[MASK]息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  氣\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲[MASK]遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  音\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息[MASK]然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  嘩\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽[MASK]，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  止\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，[MASK]他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  令\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他[MASK]長氣，心想：\"既來之，則安之。 \n",
            "建議字:  喘\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大[MASK]氣，心想：\"既來之，則安之。 \n",
            "建議字:  喘\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長[MASK]，心想：\"既來之，則安之。 \n",
            "建議字:  老\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來[MASK]，則安之。 \n",
            "建議字:  此\n",
            "預測錯字數目: 40 錯誤率 0.3669724770642202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LinNj3MoiTm",
        "colab_type": "text"
      },
      "source": [
        "# load my model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSpZjeXo8vf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b9986f28-0e37-4d96-a1b4-3a7b650b1f12"
      },
      "source": [
        "ls"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34mbert\u001b[0m/                'Neural Style Transfer with Eager Execution.ipynb'\n",
            "\u001b[01;34m'Car Detection'\u001b[0m/      \u001b[01;34m'NLP in tensorflow'\u001b[0m/\n",
            " \u001b[01;34meight\u001b[0m/                \u001b[01;34mpycorrector\u001b[0m/\n",
            " \u001b[01;34mglue\u001b[0m/                 \u001b[01;34mpytorch_transformers\u001b[0m/\n",
            " \u001b[01;34mkeras-bert\u001b[0m/           \u001b[01;34mTom-Chang-Deep-Lyrics-master\u001b[0m/\n",
            " \u001b[01;34mmachinetranslation\u001b[0m/   \u001b[01;34mudacity_intro_to_tensorflow_for_deep_learning\u001b[0m/\n",
            " \u001b[01;34mmy_chinese_lm\u001b[0m/        最重要的事.docx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7bWTpJrS2_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_path = 'my_chinese_lm'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScfIAc6tdvyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "token_dict_inv = {v: k for k, v in token_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lobFUnN3rIQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57d978c6-7d5b-40b1-8b1d-e1a30c2bc381"
      },
      "source": [
        "model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True)\n",
        "model.summary(line_length=120)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "________________________________________________________________________________________________________________________\n",
            "Layer (type)                           Output Shape               Param #       Connected to                            \n",
            "========================================================================================================================\n",
            "Input-Token (InputLayer)               [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)             [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding)       [(None, 512, 768), (21128, 16226304      Input-Token[0][0]                       \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)          (None, 512, 768)           1536          Input-Segment[0][0]                     \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)          (None, 512, 768)           0             Embedding-Token[0][0]                   \n",
            "                                                                                Embedding-Segment[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmbedding) (None, 512, 768)           393216        Embedding-Token-Segment[0][0]           \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)            (None, 512, 768)           0             Embedding-Position[0][0]                \n",
            "________________________________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalization)    (None, 512, 768)           1536          Embedding-Dropout[0][0]                 \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Embedding-Norm[0][0]                    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Embedding-Norm[0][0]                    \n",
            "                                                                                Encoder-1-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-1-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-1-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-1-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-1-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-1-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-1-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-1-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-2-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-2-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-2-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-2-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-2-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-2-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-2-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-2-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-3-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-3-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-3-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-3-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-3-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-3-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-3-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-3-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-4-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-4-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-4-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-4-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-4-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-4-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-4-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-4-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-5-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-5-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-5-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-5-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-5-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-5-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-5-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-5-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-6-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-6-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-6-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-6-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-6-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-6-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-6-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-6-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-7-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-7-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-7-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-7-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-7-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-7-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-7-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-7-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-8-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-8-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-8-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-8-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-8-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-8-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention (Mult (None, 512, 768)           2362368       Encoder-8-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Dropo (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention[0][0]  \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Add ( (None, 512, 768)           0             Encoder-8-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-9-MultiHeadSelfAttention-Dropout\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttention-Norm  (None, 512, 768)           1536          Encoder-9-MultiHeadSelfAttention-Add[0][\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForward)    (None, 512, 768)           4722432       Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout (Dropout (None, 512, 768)           0             Encoder-9-FeedForward[0][0]             \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add)        (None, 512, 768)           0             Encoder-9-MultiHeadSelfAttention-Norm[0]\n",
            "                                                                                Encoder-9-FeedForward-Dropout[0][0]     \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (LayerNorma (None, 512, 768)           1536          Encoder-9-FeedForward-Add[0][0]         \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-9-FeedForward-Norm[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-9-FeedForward-Norm[0][0]        \n",
            "                                                                                Encoder-10-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-10-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-10-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-10-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-10-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-10-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-10-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-10-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-11-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-11-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-11-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-11-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-11-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-11-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention (Mul (None, 512, 768)           2362368       Encoder-11-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Drop (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention[0][0] \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Add  (None, 512, 768)           0             Encoder-11-FeedForward-Norm[0][0]       \n",
            "                                                                                Encoder-12-MultiHeadSelfAttention-Dropou\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttention-Norm (None, 512, 768)           1536          Encoder-12-MultiHeadSelfAttention-Add[0]\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedForward)   (None, 512, 768)           4722432       Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout (Dropou (None, 512, 768)           0             Encoder-12-FeedForward[0][0]            \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add)       (None, 512, 768)           0             Encoder-12-MultiHeadSelfAttention-Norm[0\n",
            "                                                                                Encoder-12-FeedForward-Dropout[0][0]    \n",
            "________________________________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (LayerNorm (None, 512, 768)           1536          Encoder-12-FeedForward-Add[0][0]        \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)                      (None, 512, 768)           590592        Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)          (None, 512, 768)           1536          MLM-Dense[0][0]                         \n",
            "________________________________________________________________________________________________________________________\n",
            "Extract (Extract)                      (None, 768)                0             Encoder-12-FeedForward-Norm[0][0]       \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)          (None, 512, 21128)         21128         MLM-Norm[0][0]                          \n",
            "                                                                                Embedding-Token[0][1]                   \n",
            "________________________________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)              [(None, 512)]              0                                                     \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)                      (None, 768)                590592        Extract[0][0]                           \n",
            "________________________________________________________________________________________________________________________\n",
            "MLM (Masked)                           (None, 512, 21128)         0             MLM-Sim[0][0]                           \n",
            "                                                                                Input-Masked[0][0]                      \n",
            "________________________________________________________________________________________________________________________\n",
            "NSP (Dense)                            (None, 2)                  1538          NSP-Dense[0][0]                         \n",
            "========================================================================================================================\n",
            "Total params: 102,882,442\n",
            "Trainable params: 102,882,442\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhbM2ngasGuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(token_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnK16fxseDUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "masks = np.array([[0, 1, 1] + [0] * (512 - 3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v55wFcv_peRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dc012eb-0093-4337-c684-84189bf6c78e"
      },
      "source": [
        "text = '吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。'\n",
        "text_wrong = 0\n",
        "for i in range(0,len(tokens)):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  if tokens[i] in ['，','。','、','[CLS]','[SEP]','：','\"','！']:\n",
        "      continue\n",
        "  tokens[i] = '[MASK]'\n",
        "  # print(tokens)\n",
        "  indices = np.array([[token_dict[token] for token in tokens] + [0] * (512 - len(tokens))])\n",
        "  segments = np.array([[0] * len(tokens) + [0] * (512 - len(tokens))])\n",
        "  masks = np.array([[0, 1, 1] + [0] * (512 - 3)])\n",
        "  \n",
        "  predicts = model.predict([indices, segments, masks])[0].argmax(axis=-1).tolist()\n",
        "  sentences= list(map(lambda x: token_dict_inv[x], predicts[0][i:i+1]))\n",
        "  if ''.join(sentences) != text[i-1] :\n",
        "    print(''.join(tokens[1:len(tokens)-1]), '\\n建議字: ', ''.join(sentences))\n",
        "    text_wrong += 1\n",
        "print('預測錯字數目:',text_wrong,'錯誤率',text_wrong/len(tokens))   "
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MASK]光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  李\n",
            "吳[MASK]勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  百\n",
            "吳光[MASK]打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  榮\n",
            "吳光勝[MASK]開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  推\n",
            "吳光勝打開[MASK]門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  木\n",
            "吳光勝打開房門，[MASK]游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  大\n",
            "吳光勝打開房門，鬱[MASK]標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  錦\n",
            "吳光勝打開房門，鬱游[MASK]在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  隱\n",
            "吳光勝打開房門，鬱游標在他[MASK]上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  身\n",
            "吳光勝打開房門，鬱游標在他背[MASK]重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  後\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，[MASK]進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  鑽\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推[MASK]門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  入\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進[MASK]內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  屋\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門[MASK]，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  來\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，[MASK]即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  當\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上[MASK]門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  房\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇[MASK]\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  聲\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你[MASK]無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  對\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講[MASK]不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  話\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不[MASK]？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  理\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講[MASK]這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  ，\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？[MASK]可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  你\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這[MASK]不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  人\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是[MASK]我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  將\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當[MASK]了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  成\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了[MASK]人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  敵\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了[MASK]？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  麼\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍[MASK]不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  既\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是[MASK]府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  地\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官[MASK]，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  吏\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂[MASK]人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  殺\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關[MASK]？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  門\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面[MASK]息遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  氣\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲[MASK]遽然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  音\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息[MASK]然，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  蕩\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽[MASK]，任他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  減\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，[MASK]他大長氣，心想：\"既來之，則安之。 \n",
            "建議字:  令\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他[MASK]長氣，心想：\"既來之，則安之。 \n",
            "建議字:  喘\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大[MASK]氣，心想：\"既來之，則安之。 \n",
            "建議字:  口\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長[MASK]，心想：\"既來之，則安之。 \n",
            "建議字:  老\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來[MASK]，則安之。 \n",
            "建議字:  此\n",
            "吳光勝打開房門，鬱游標在他背上重重一推，推進門內，隨即關上木門，只聽得喀喇一\"你們無量劍講理不講？這可不是把我當作了犯人了嗎？無量劍又不是官府，怎能胡亂關人？\"可是外面聲息遽然，任他大長氣，心想：\"既來之，則[MASK]之。 \n",
            "建議字:  去\n",
            "預測錯字數目: 42 錯誤率 0.3853211009174312\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}