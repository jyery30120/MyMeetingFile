{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrrKhMv9Ss23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1cc657d9-312f-4ca5-a319-6872d0ed6bec"
      },
      "source": [
        "!pip install tqdm boto3 requests regex -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10kB 15.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 655kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tudwKB-2S7qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44da5b95-8e47-4548-acd3-1edda1ff6d32"
      },
      "source": [
        "import torch\n",
        "from IPython.display import clear_output\n",
        "\n",
        "GITHUB_REPO = \"huggingface/pytorch-pretrained-BERT\" # 感謝 HuggingFace 團隊造福後人\n",
        "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定繁簡中文 BERT-BASE 預訓練模型\n",
        "\n",
        "# 取得此預訓練模型所使用的 tokenizer\n",
        "tokenizer = torch.hub.load(GITHUB_REPO, 'bertTokenizer', PRETRAINED_MODEL_NAME)\n",
        "\n",
        "clear_output()\n",
        "print(\"PyTorch 版本：\", torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 版本： 1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_3y6jAWS_sZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80b4dde9-0508-46f0-9601-326d79cb1266"
      },
      "source": [
        "vocab = tokenizer.vocab\n",
        "print(\"字典大小：\", len(vocab))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "字典大小： 21128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWUBYhZ1TiSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0316cd22-cba0-415b-8c4d-0fc5f9004fbb"
      },
      "source": [
        "import random\n",
        "random_tokens = random.sample(list(vocab), 10)\n",
        "random_ids = [vocab[t] for t in random_tokens]\n",
        "\n",
        "print(\"{0:20}{1:15}\".format(\"token\", \"index\"))\n",
        "print(\"-\" * 25)\n",
        "for t, id in zip(random_tokens, random_ids):\n",
        "    print(\"{0:15}{1:10}\".format(t, id))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "token               index          \n",
            "-------------------------\n",
            "蕎                    5935\n",
            "##緞                 18280\n",
            "‖                     337\n",
            "##ς                 13395\n",
            "##則                 14236\n",
            "谷                    6484\n",
            "266                  9674\n",
            "彤                    2502\n",
            "##箕                 18106\n",
            "##mate              12125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGdCS5ObTqtk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d55a5364-6498-45f9-da89-14a3ba9ccdde"
      },
      "source": [
        "indices = list(range(647, 657))\n",
        "some_pairs = [(t, idx) for t, idx in vocab.items() if idx in indices]\n",
        "for pair in some_pairs:\n",
        "    print(pair)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('ㄅ', 647)\n",
            "('ㄆ', 648)\n",
            "('ㄇ', 649)\n",
            "('ㄉ', 650)\n",
            "('ㄋ', 651)\n",
            "('ㄌ', 652)\n",
            "('ㄍ', 653)\n",
            "('ㄎ', 654)\n",
            "('ㄏ', 655)\n",
            "('ㄒ', 656)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO1gIT_GUrIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "385886c6-e9e0-40e6-e4dd-f4437fa860f1"
      },
      "source": [
        "text = \"[CLS] 等到潮水 [MASK] 了，就知道誰沒穿褲子。\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(text)\n",
        "print(tokens[:10], '...')\n",
        "print(ids[:10], '...')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 等到潮水 [MASK] 了，就知道誰沒穿褲子。\n",
            "['[CLS]', '等', '到', '潮', '水', '[MASK]', '了', '，', '就', '知'] ...\n",
            "[101, 5023, 1168, 4060, 3717, 103, 749, 8024, 2218, 4761] ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU0WgkFkbKxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b219546-5131-4579-b86a-9380873d532d"
      },
      "source": [
        "maskedLM_model = torch.hub.load(GITHUB_REPO, \n",
        "                                'bertForMaskedLM', \n",
        "                                PRETRAINED_MODEL_NAME)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/huggingface_pytorch-pretrained-BERT_master\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kliFlJwsW1J-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "87250a84-4286-4ced-99a1-5e3ca2f2ee9b"
      },
      "source": [
        "masked = '[MASK]'\n",
        "#text = \"等到潮水退了，就知道誰沒穿褲子。\"\n",
        "text = input(\"輸入句子： \\n\")\n",
        "text = ''.join(text.split())\n",
        "for j in range(0,len(text)):\n",
        "    if text[j] in ['，','。']:\n",
        "      continue\n",
        "    mask_text = text.replace(text[j:j+1],masked)\n",
        "    mask_text = '[CLS] ' + mask_text\n",
        "    #print(mask_text)\n",
        "    tokens = tokenizer.tokenize(mask_text)\n",
        "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    #print(tokens)\n",
        "    #print(ids)\n",
        "    tokens_tensor = torch.tensor([ids])  # (1, seq_len)\n",
        "    segments_tensors = torch.zeros_like(tokens_tensor)  # (1, seq_len)\n",
        "    #maskedLM_model = torch.hub.load(GITHUB_REPO, \n",
        "    #                            'bertForMaskedLM', \n",
        "    #                            PRETRAINED_MODEL_NAME)\n",
        "    \n",
        "    maskedLM_model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = maskedLM_model(tokens_tensor, segments_tensors)\n",
        "        predictions = outputs[0]\n",
        "    # (1, seq_len, num_hidden_units)\n",
        "    #del maskedLM_model\n",
        "    \n",
        "    masked_index = j+1\n",
        "    #masked_index = 5\n",
        "    k = 5\n",
        "    probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)\n",
        "    predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())\n",
        "    predicted_tokens_prob= []\n",
        "    #print(predicted_tokens)\n",
        "    \n",
        "    for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):\n",
        "        tokens[masked_index] = t\n",
        "        prob = \"{:2}%\".format(int(p.item()*100))\n",
        "        predicted_tokens_prob.append( prob )\n",
        "    \n",
        "    if(text[j] not in predicted_tokens):\n",
        "        detect_sentence =  text[:j] +\"\\033[35m \"+text[j]+\" \\033[0m\" +text[j+1:]\n",
        "        print('錯字預測:',detect_sentence)\n",
        "        candid = zip(predicted_tokens[:5],predicted_tokens_prob[:5])\n",
        "        print('建議字:', list(candid))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "輸入句子： \n",
            "等到潮水退了，就知道誰沒穿褲子。\n",
            "錯字預測: 等到潮水\u001b[35m 退 \u001b[0m了，就知道誰沒穿褲子。\n",
            "建議字: [('來', '67%'), ('濕', '25%'), ('過', ' 2%'), ('流', ' 0%'), ('走', ' 0%')]\n",
            "錯字預測: 等到潮水退了，就知道\u001b[35m 誰 \u001b[0m沒穿褲子。\n",
            "建議字: [('我', '53%'), ('你', '12%'), ('他', '11%'), ('她', ' 7%'), ('還', ' 5%')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}